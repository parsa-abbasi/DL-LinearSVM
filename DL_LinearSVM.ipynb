{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_LinearSVM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        "<h2>Deep Learning using Linear Support Vector Machines</h2>\n",
        "<p>by <i>Yichuan Tang</i></p>\n",
        "<a href=\"http://arxiv.org/abs/1306.0239\">http://arxiv.org/abs/1306.0239</a>\n",
        "</center>\n",
        "<p><b>Abstract: </b>Recently, fully-connected and convolutional neural networks have been trained to achieve state-of-the-art performance on a wide variety of tasks such as speech recognition, image classification, natural language processing, and bioinformatics. For classification tasks, most of these \"deep learning\" models employ the softmax activation function for prediction and minimize cross-entropy loss. In this paper, we demonstrate a small but consistent advantage of replacing the softmax layer with a linear support vector machine. Learning minimizes a margin-based loss instead of the cross-entropy loss. While there have been various combinations of neural nets and SVMs in prior art, our results using L2-SVMs show that by simply replacing softmax with linear SVMs gives significant gains on popular deep learning datasets MNIST, CIFAR-10, and the ICML 2013 Representation Learning Workshop's face expression recognition challenge.</p>"
      ],
      "metadata": {
        "id": "1hkyFdAWMq25"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Libraries"
      ],
      "metadata": {
        "id": "HVsWL1souUmj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1gE-xt63Fv2p"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from keras.datasets import mnist, cifar10\n",
        "from keras.layers import Dense, Dropout, Input, Conv2D, MaxPooling2D, Flatten, BatchNormalization\n",
        "from keras.layers import GaussianNoise\n",
        "from keras.models import Model\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.regularizers import l2\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SVM Loss Function"
      ],
      "metadata": {
        "id": "xlyEzdelumAU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following loss fuction is based on the presented formula in [this course](https://cs231n.github.io/linear-classify/#multiclass-support-vector-machine-loss).\n",
        "\n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1ioDXTGPsD9vzbcVkBwQBOqa2CTw9gxa8\"\n",
        "</center>"
      ],
      "metadata": {
        "id": "se6E0TvU2xT7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def svm_loss(layer, reg_weight=1, loss_weight=1):\n",
        "    weights = layer.weights[0]\n",
        "    weights_tf = tf.convert_to_tensor(weights)\n",
        "    \n",
        "    def squared_categorical_hinge_loss(y_true, y_pred):\n",
        "        pos = K.sum(y_true * y_pred, axis=-1)\n",
        "        neg = K.max((1.0 - y_true) * y_pred, axis=-1)\n",
        "        hinge_loss = K.mean(K.square(K.maximum(0.0, 1.0 - pos + neg)), axis=-1)\n",
        "        regularization_loss = tf.reduce_sum(tf.square(weights_tf))\n",
        "        return reg_weight*regularization_loss + loss_weight*hinge_loss\n",
        "    \n",
        "    return squared_categorical_hinge_loss"
      ],
      "metadata": {
        "id": "Gc5ZQRcbF3Gj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MNIST"
      ],
      "metadata": {
        "id": "oNqNr1nXHiHQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset"
      ],
      "metadata": {
        "id": "yfjxdnjJuWhc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHWZpzXC9CdL",
        "outputId": "7467ff72-083c-44eb-a4e2-84c0a65e48d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 10\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes)"
      ],
      "metadata": {
        "id": "_-WeNoKU9GO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train.reshape(60000, 784)\n",
        "x_test = x_test.reshape(10000, 784)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255.\n",
        "x_test /= 255.\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5ZjWJpb9iZ1",
        "outputId": "5a7ac850-6dc4-443c-fa12-a0f3bfb42429"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60000 train samples\n",
            "10000 test samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PCA"
      ],
      "metadata": {
        "id": "AOuFNTG_uhqH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "scalar = StandardScaler()\n",
        "scaled_x_train = scalar.fit_transform(x_train)\n",
        "scaled_x_test = scalar.transform(x_test)"
      ],
      "metadata": {
        "id": "Q5ZegQNP9SIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca = PCA(n_components = 70)\n",
        "pca.fit(scaled_x_train)\n",
        "x_train = pca.transform(scaled_x_train)\n",
        "print('x_train pca shape:', x_train.shape)\n",
        "x_test = pca.transform(scaled_x_test)\n",
        "print('x_test pca shape:', x_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4gCZK8C9zpw",
        "outputId": "89c484fa-1f9c-4a67-ebf8-37ae5b02087f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train pca shape: (60000, 70)\n",
            "x_test pca shape: (10000, 70)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SVM Model"
      ],
      "metadata": {
        "id": "_pIYfLtzupRE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The original paper suggested a fully conneted model with the following specification:\n",
        "\n",
        "\n",
        "*   Two hidden layer of 512 units\n",
        "*   300 minibatches of 200 samples each\n",
        "*   Stocastic gradiant descent wit momentum\n",
        "*   Learning rate is linearly decayed from 0.1 to 0.0\n",
        "*   A lot of Gaussian noise is added to the input. Noise of standard deviation of 1.0.\n",
        "\n",
        "But the problems of the paper are:\n",
        "\n",
        "\n",
        "*   It didn't specified the momentum value.\n",
        "*   The batch size is better to be a power of two (like 256).\n",
        "*   And most importantly it didn't specified the penalty value of hinge loss.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rkBkdlA14cqs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(GaussianNoise(1.0, input_shape=(x_train.shape[1],)))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(10, use_bias=False, activation='tanh', name='svm'))"
      ],
      "metadata": {
        "id": "zypQ5miFA6Kp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.SGD(learning_rate=0.0005,\n",
        "                                    decay=0.0005/400,\n",
        "                                    momentum=0.9)\n",
        "model.compile(optimizer = optimizer,\n",
        "              loss = svm_loss(model.get_layer('svm'), 0.5, 0.5),\n",
        "              metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "wbdGehLTF4eD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 256\n",
        "epochs = 400\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size = batch_size,\n",
        "                    epochs = epochs,\n",
        "                    verbose = 1,\n",
        "                    validation_data = (x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KW79MC-BF5lS",
        "outputId": "1ad03df3-4e9b-4acf-db3a-d46bbc64de13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.5507 - accuracy: 0.4717 - val_loss: 10.4739 - val_accuracy: 0.6456\n",
            "Epoch 2/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.4820 - accuracy: 0.6026 - val_loss: 10.4665 - val_accuracy: 0.6991\n",
            "Epoch 3/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 10.4768 - accuracy: 0.6477 - val_loss: 10.4558 - val_accuracy: 0.7318\n",
            "Epoch 4/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.4681 - accuracy: 0.6811 - val_loss: 10.4297 - val_accuracy: 0.7628\n",
            "Epoch 5/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 10.4383 - accuracy: 0.7214 - val_loss: 10.3545 - val_accuracy: 0.8103\n",
            "Epoch 6/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 10.3277 - accuracy: 0.7877 - val_loss: 10.2008 - val_accuracy: 0.8761\n",
            "Epoch 7/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.2357 - accuracy: 0.8503 - val_loss: 10.1576 - val_accuracy: 0.9018\n",
            "Epoch 8/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 10.2014 - accuracy: 0.8731 - val_loss: 10.1378 - val_accuracy: 0.9137\n",
            "Epoch 9/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.1822 - accuracy: 0.8841 - val_loss: 10.1249 - val_accuracy: 0.9214\n",
            "Epoch 10/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.1689 - accuracy: 0.8921 - val_loss: 10.1163 - val_accuracy: 0.9276\n",
            "Epoch 11/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 10.1573 - accuracy: 0.8999 - val_loss: 10.1093 - val_accuracy: 0.9318\n",
            "Epoch 12/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 10.1508 - accuracy: 0.9030 - val_loss: 10.1043 - val_accuracy: 0.9331\n",
            "Epoch 13/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.1452 - accuracy: 0.9062 - val_loss: 10.1005 - val_accuracy: 0.9360\n",
            "Epoch 14/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.1395 - accuracy: 0.9104 - val_loss: 10.0964 - val_accuracy: 0.9381\n",
            "Epoch 15/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.1331 - accuracy: 0.9140 - val_loss: 10.0918 - val_accuracy: 0.9403\n",
            "Epoch 16/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.1296 - accuracy: 0.9165 - val_loss: 10.0894 - val_accuracy: 0.9420\n",
            "Epoch 17/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.1237 - accuracy: 0.9193 - val_loss: 10.0860 - val_accuracy: 0.9431\n",
            "Epoch 18/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 10.1212 - accuracy: 0.9216 - val_loss: 10.0841 - val_accuracy: 0.9448\n",
            "Epoch 19/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.1187 - accuracy: 0.9231 - val_loss: 10.0817 - val_accuracy: 0.9459\n",
            "Epoch 20/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.1151 - accuracy: 0.9253 - val_loss: 10.0796 - val_accuracy: 0.9467\n",
            "Epoch 21/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.1122 - accuracy: 0.9261 - val_loss: 10.0777 - val_accuracy: 0.9476\n",
            "Epoch 22/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.1094 - accuracy: 0.9288 - val_loss: 10.0763 - val_accuracy: 0.9483\n",
            "Epoch 23/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.1069 - accuracy: 0.9296 - val_loss: 10.0743 - val_accuracy: 0.9496\n",
            "Epoch 24/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.1063 - accuracy: 0.9299 - val_loss: 10.0731 - val_accuracy: 0.9503\n",
            "Epoch 25/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.1037 - accuracy: 0.9319 - val_loss: 10.0716 - val_accuracy: 0.9508\n",
            "Epoch 26/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.1029 - accuracy: 0.9317 - val_loss: 10.0707 - val_accuracy: 0.9524\n",
            "Epoch 27/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0994 - accuracy: 0.9352 - val_loss: 10.0687 - val_accuracy: 0.9532\n",
            "Epoch 28/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0974 - accuracy: 0.9352 - val_loss: 10.0678 - val_accuracy: 0.9537\n",
            "Epoch 29/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0967 - accuracy: 0.9368 - val_loss: 10.0667 - val_accuracy: 0.9539\n",
            "Epoch 30/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0949 - accuracy: 0.9375 - val_loss: 10.0653 - val_accuracy: 0.9550\n",
            "Epoch 31/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0932 - accuracy: 0.9371 - val_loss: 10.0645 - val_accuracy: 0.9552\n",
            "Epoch 32/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0911 - accuracy: 0.9392 - val_loss: 10.0636 - val_accuracy: 0.9563\n",
            "Epoch 33/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 10.0895 - accuracy: 0.9412 - val_loss: 10.0629 - val_accuracy: 0.9560\n",
            "Epoch 34/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0903 - accuracy: 0.9401 - val_loss: 10.0619 - val_accuracy: 0.9566\n",
            "Epoch 35/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 10.0893 - accuracy: 0.9409 - val_loss: 10.0605 - val_accuracy: 0.9574\n",
            "Epoch 36/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0865 - accuracy: 0.9417 - val_loss: 10.0600 - val_accuracy: 0.9581\n",
            "Epoch 37/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0861 - accuracy: 0.9429 - val_loss: 10.0593 - val_accuracy: 0.9576\n",
            "Epoch 38/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0844 - accuracy: 0.9437 - val_loss: 10.0583 - val_accuracy: 0.9582\n",
            "Epoch 39/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0839 - accuracy: 0.9439 - val_loss: 10.0576 - val_accuracy: 0.9590\n",
            "Epoch 40/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0825 - accuracy: 0.9443 - val_loss: 10.0575 - val_accuracy: 0.9582\n",
            "Epoch 41/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0827 - accuracy: 0.9434 - val_loss: 10.0567 - val_accuracy: 0.9590\n",
            "Epoch 42/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0812 - accuracy: 0.9443 - val_loss: 10.0560 - val_accuracy: 0.9592\n",
            "Epoch 43/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0806 - accuracy: 0.9458 - val_loss: 10.0553 - val_accuracy: 0.9596\n",
            "Epoch 44/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0799 - accuracy: 0.9462 - val_loss: 10.0545 - val_accuracy: 0.9605\n",
            "Epoch 45/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0787 - accuracy: 0.9461 - val_loss: 10.0541 - val_accuracy: 0.9595\n",
            "Epoch 46/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0790 - accuracy: 0.9457 - val_loss: 10.0537 - val_accuracy: 0.9604\n",
            "Epoch 47/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0764 - accuracy: 0.9481 - val_loss: 10.0533 - val_accuracy: 0.9602\n",
            "Epoch 48/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 10.0762 - accuracy: 0.9483 - val_loss: 10.0532 - val_accuracy: 0.9600\n",
            "Epoch 49/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 10.0764 - accuracy: 0.9481 - val_loss: 10.0526 - val_accuracy: 0.9600\n",
            "Epoch 50/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0749 - accuracy: 0.9486 - val_loss: 10.0517 - val_accuracy: 0.9615\n",
            "Epoch 51/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0744 - accuracy: 0.9492 - val_loss: 10.0510 - val_accuracy: 0.9612\n",
            "Epoch 52/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0723 - accuracy: 0.9503 - val_loss: 10.0508 - val_accuracy: 0.9614\n",
            "Epoch 53/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0730 - accuracy: 0.9497 - val_loss: 10.0502 - val_accuracy: 0.9618\n",
            "Epoch 54/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0726 - accuracy: 0.9496 - val_loss: 10.0495 - val_accuracy: 0.9621\n",
            "Epoch 55/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0725 - accuracy: 0.9489 - val_loss: 10.0497 - val_accuracy: 0.9616\n",
            "Epoch 56/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0719 - accuracy: 0.9507 - val_loss: 10.0489 - val_accuracy: 0.9629\n",
            "Epoch 57/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0695 - accuracy: 0.9517 - val_loss: 10.0484 - val_accuracy: 0.9628\n",
            "Epoch 58/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0700 - accuracy: 0.9518 - val_loss: 10.0483 - val_accuracy: 0.9628\n",
            "Epoch 59/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 10.0684 - accuracy: 0.9521 - val_loss: 10.0475 - val_accuracy: 0.9624\n",
            "Epoch 60/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0694 - accuracy: 0.9515 - val_loss: 10.0472 - val_accuracy: 0.9638\n",
            "Epoch 61/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0675 - accuracy: 0.9535 - val_loss: 10.0467 - val_accuracy: 0.9634\n",
            "Epoch 62/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0673 - accuracy: 0.9526 - val_loss: 10.0463 - val_accuracy: 0.9637\n",
            "Epoch 63/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0670 - accuracy: 0.9530 - val_loss: 10.0463 - val_accuracy: 0.9642\n",
            "Epoch 64/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0684 - accuracy: 0.9525 - val_loss: 10.0458 - val_accuracy: 0.9652\n",
            "Epoch 65/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0660 - accuracy: 0.9531 - val_loss: 10.0456 - val_accuracy: 0.9651\n",
            "Epoch 66/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0654 - accuracy: 0.9535 - val_loss: 10.0450 - val_accuracy: 0.9653\n",
            "Epoch 67/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0655 - accuracy: 0.9543 - val_loss: 10.0450 - val_accuracy: 0.9654\n",
            "Epoch 68/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0642 - accuracy: 0.9542 - val_loss: 10.0442 - val_accuracy: 0.9657\n",
            "Epoch 69/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0645 - accuracy: 0.9549 - val_loss: 10.0441 - val_accuracy: 0.9655\n",
            "Epoch 70/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0635 - accuracy: 0.9550 - val_loss: 10.0441 - val_accuracy: 0.9657\n",
            "Epoch 71/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0636 - accuracy: 0.9544 - val_loss: 10.0437 - val_accuracy: 0.9657\n",
            "Epoch 72/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0629 - accuracy: 0.9557 - val_loss: 10.0435 - val_accuracy: 0.9660\n",
            "Epoch 73/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0619 - accuracy: 0.9557 - val_loss: 10.0436 - val_accuracy: 0.9659\n",
            "Epoch 74/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0617 - accuracy: 0.9549 - val_loss: 10.0431 - val_accuracy: 0.9664\n",
            "Epoch 75/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0631 - accuracy: 0.9564 - val_loss: 10.0429 - val_accuracy: 0.9669\n",
            "Epoch 76/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0602 - accuracy: 0.9569 - val_loss: 10.0425 - val_accuracy: 0.9659\n",
            "Epoch 77/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0603 - accuracy: 0.9568 - val_loss: 10.0422 - val_accuracy: 0.9670\n",
            "Epoch 78/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0602 - accuracy: 0.9567 - val_loss: 10.0421 - val_accuracy: 0.9667\n",
            "Epoch 79/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0593 - accuracy: 0.9577 - val_loss: 10.0418 - val_accuracy: 0.9667\n",
            "Epoch 80/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0607 - accuracy: 0.9552 - val_loss: 10.0413 - val_accuracy: 0.9671\n",
            "Epoch 81/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0587 - accuracy: 0.9571 - val_loss: 10.0409 - val_accuracy: 0.9681\n",
            "Epoch 82/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0586 - accuracy: 0.9579 - val_loss: 10.0410 - val_accuracy: 0.9677\n",
            "Epoch 83/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0592 - accuracy: 0.9572 - val_loss: 10.0413 - val_accuracy: 0.9675\n",
            "Epoch 84/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 10.0587 - accuracy: 0.9582 - val_loss: 10.0404 - val_accuracy: 0.9681\n",
            "Epoch 85/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0576 - accuracy: 0.9577 - val_loss: 10.0404 - val_accuracy: 0.9684\n",
            "Epoch 86/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0578 - accuracy: 0.9580 - val_loss: 10.0402 - val_accuracy: 0.9687\n",
            "Epoch 87/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0583 - accuracy: 0.9575 - val_loss: 10.0402 - val_accuracy: 0.9689\n",
            "Epoch 88/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0576 - accuracy: 0.9587 - val_loss: 10.0399 - val_accuracy: 0.9687\n",
            "Epoch 89/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0561 - accuracy: 0.9599 - val_loss: 10.0397 - val_accuracy: 0.9684\n",
            "Epoch 90/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0566 - accuracy: 0.9585 - val_loss: 10.0395 - val_accuracy: 0.9681\n",
            "Epoch 91/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0565 - accuracy: 0.9590 - val_loss: 10.0389 - val_accuracy: 0.9686\n",
            "Epoch 92/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0566 - accuracy: 0.9593 - val_loss: 10.0391 - val_accuracy: 0.9692\n",
            "Epoch 93/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0564 - accuracy: 0.9592 - val_loss: 10.0384 - val_accuracy: 0.9695\n",
            "Epoch 94/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 10.0549 - accuracy: 0.9603 - val_loss: 10.0385 - val_accuracy: 0.9688\n",
            "Epoch 95/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 10.0554 - accuracy: 0.9590 - val_loss: 10.0384 - val_accuracy: 0.9692\n",
            "Epoch 96/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0536 - accuracy: 0.9608 - val_loss: 10.0381 - val_accuracy: 0.9696\n",
            "Epoch 97/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0544 - accuracy: 0.9603 - val_loss: 10.0378 - val_accuracy: 0.9694\n",
            "Epoch 98/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0551 - accuracy: 0.9603 - val_loss: 10.0379 - val_accuracy: 0.9697\n",
            "Epoch 99/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0544 - accuracy: 0.9611 - val_loss: 10.0377 - val_accuracy: 0.9694\n",
            "Epoch 100/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0529 - accuracy: 0.9612 - val_loss: 10.0379 - val_accuracy: 0.9693\n",
            "Epoch 101/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 10.0527 - accuracy: 0.9609 - val_loss: 10.0373 - val_accuracy: 0.9694\n",
            "Epoch 102/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 10.0520 - accuracy: 0.9621 - val_loss: 10.0373 - val_accuracy: 0.9702\n",
            "Epoch 103/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0529 - accuracy: 0.9610 - val_loss: 10.0369 - val_accuracy: 0.9695\n",
            "Epoch 104/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0529 - accuracy: 0.9618 - val_loss: 10.0373 - val_accuracy: 0.9704\n",
            "Epoch 105/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0521 - accuracy: 0.9612 - val_loss: 10.0366 - val_accuracy: 0.9699\n",
            "Epoch 106/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0514 - accuracy: 0.9629 - val_loss: 10.0366 - val_accuracy: 0.9693\n",
            "Epoch 107/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0532 - accuracy: 0.9613 - val_loss: 10.0365 - val_accuracy: 0.9696\n",
            "Epoch 108/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0520 - accuracy: 0.9611 - val_loss: 10.0364 - val_accuracy: 0.9703\n",
            "Epoch 109/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0518 - accuracy: 0.9620 - val_loss: 10.0362 - val_accuracy: 0.9699\n",
            "Epoch 110/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0502 - accuracy: 0.9629 - val_loss: 10.0361 - val_accuracy: 0.9702\n",
            "Epoch 111/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0518 - accuracy: 0.9620 - val_loss: 10.0360 - val_accuracy: 0.9701\n",
            "Epoch 112/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0508 - accuracy: 0.9619 - val_loss: 10.0357 - val_accuracy: 0.9708\n",
            "Epoch 113/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0510 - accuracy: 0.9624 - val_loss: 10.0357 - val_accuracy: 0.9701\n",
            "Epoch 114/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0507 - accuracy: 0.9625 - val_loss: 10.0355 - val_accuracy: 0.9702\n",
            "Epoch 115/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0505 - accuracy: 0.9621 - val_loss: 10.0354 - val_accuracy: 0.9701\n",
            "Epoch 116/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0491 - accuracy: 0.9634 - val_loss: 10.0353 - val_accuracy: 0.9709\n",
            "Epoch 117/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0495 - accuracy: 0.9630 - val_loss: 10.0351 - val_accuracy: 0.9707\n",
            "Epoch 118/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0496 - accuracy: 0.9629 - val_loss: 10.0352 - val_accuracy: 0.9706\n",
            "Epoch 119/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0497 - accuracy: 0.9636 - val_loss: 10.0348 - val_accuracy: 0.9712\n",
            "Epoch 120/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0491 - accuracy: 0.9637 - val_loss: 10.0347 - val_accuracy: 0.9714\n",
            "Epoch 121/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0490 - accuracy: 0.9625 - val_loss: 10.0345 - val_accuracy: 0.9709\n",
            "Epoch 122/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0490 - accuracy: 0.9636 - val_loss: 10.0343 - val_accuracy: 0.9707\n",
            "Epoch 123/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0485 - accuracy: 0.9642 - val_loss: 10.0342 - val_accuracy: 0.9710\n",
            "Epoch 124/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0481 - accuracy: 0.9645 - val_loss: 10.0343 - val_accuracy: 0.9706\n",
            "Epoch 125/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0482 - accuracy: 0.9637 - val_loss: 10.0338 - val_accuracy: 0.9714\n",
            "Epoch 126/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0466 - accuracy: 0.9648 - val_loss: 10.0342 - val_accuracy: 0.9712\n",
            "Epoch 127/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0469 - accuracy: 0.9646 - val_loss: 10.0337 - val_accuracy: 0.9711\n",
            "Epoch 128/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0470 - accuracy: 0.9645 - val_loss: 10.0336 - val_accuracy: 0.9711\n",
            "Epoch 129/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0474 - accuracy: 0.9645 - val_loss: 10.0335 - val_accuracy: 0.9719\n",
            "Epoch 130/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0466 - accuracy: 0.9647 - val_loss: 10.0335 - val_accuracy: 0.9723\n",
            "Epoch 131/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0467 - accuracy: 0.9653 - val_loss: 10.0336 - val_accuracy: 0.9714\n",
            "Epoch 132/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0463 - accuracy: 0.9651 - val_loss: 10.0334 - val_accuracy: 0.9712\n",
            "Epoch 133/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0464 - accuracy: 0.9642 - val_loss: 10.0332 - val_accuracy: 0.9724\n",
            "Epoch 134/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0462 - accuracy: 0.9645 - val_loss: 10.0334 - val_accuracy: 0.9720\n",
            "Epoch 135/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0457 - accuracy: 0.9655 - val_loss: 10.0330 - val_accuracy: 0.9723\n",
            "Epoch 136/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0455 - accuracy: 0.9650 - val_loss: 10.0327 - val_accuracy: 0.9726\n",
            "Epoch 137/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0461 - accuracy: 0.9651 - val_loss: 10.0331 - val_accuracy: 0.9725\n",
            "Epoch 138/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0457 - accuracy: 0.9654 - val_loss: 10.0329 - val_accuracy: 0.9716\n",
            "Epoch 139/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0448 - accuracy: 0.9660 - val_loss: 10.0327 - val_accuracy: 0.9727\n",
            "Epoch 140/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0455 - accuracy: 0.9652 - val_loss: 10.0326 - val_accuracy: 0.9722\n",
            "Epoch 141/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0459 - accuracy: 0.9652 - val_loss: 10.0327 - val_accuracy: 0.9718\n",
            "Epoch 142/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0445 - accuracy: 0.9664 - val_loss: 10.0324 - val_accuracy: 0.9722\n",
            "Epoch 143/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0444 - accuracy: 0.9666 - val_loss: 10.0324 - val_accuracy: 0.9718\n",
            "Epoch 144/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0439 - accuracy: 0.9670 - val_loss: 10.0324 - val_accuracy: 0.9721\n",
            "Epoch 145/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0437 - accuracy: 0.9658 - val_loss: 10.0323 - val_accuracy: 0.9721\n",
            "Epoch 146/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0438 - accuracy: 0.9661 - val_loss: 10.0320 - val_accuracy: 0.9724\n",
            "Epoch 147/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0451 - accuracy: 0.9654 - val_loss: 10.0321 - val_accuracy: 0.9724\n",
            "Epoch 148/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0437 - accuracy: 0.9664 - val_loss: 10.0315 - val_accuracy: 0.9726\n",
            "Epoch 149/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0443 - accuracy: 0.9661 - val_loss: 10.0318 - val_accuracy: 0.9721\n",
            "Epoch 150/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0437 - accuracy: 0.9663 - val_loss: 10.0315 - val_accuracy: 0.9729\n",
            "Epoch 151/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0438 - accuracy: 0.9662 - val_loss: 10.0314 - val_accuracy: 0.9727\n",
            "Epoch 152/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0431 - accuracy: 0.9666 - val_loss: 10.0315 - val_accuracy: 0.9733\n",
            "Epoch 153/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0430 - accuracy: 0.9668 - val_loss: 10.0315 - val_accuracy: 0.9727\n",
            "Epoch 154/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0426 - accuracy: 0.9671 - val_loss: 10.0316 - val_accuracy: 0.9732\n",
            "Epoch 155/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0430 - accuracy: 0.9664 - val_loss: 10.0311 - val_accuracy: 0.9728\n",
            "Epoch 156/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0430 - accuracy: 0.9669 - val_loss: 10.0311 - val_accuracy: 0.9730\n",
            "Epoch 157/400\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 10.0422 - accuracy: 0.9675 - val_loss: 10.0312 - val_accuracy: 0.9725\n",
            "Epoch 158/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0420 - accuracy: 0.9666 - val_loss: 10.0310 - val_accuracy: 0.9735\n",
            "Epoch 159/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0427 - accuracy: 0.9674 - val_loss: 10.0310 - val_accuracy: 0.9723\n",
            "Epoch 160/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0435 - accuracy: 0.9663 - val_loss: 10.0308 - val_accuracy: 0.9733\n",
            "Epoch 161/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0418 - accuracy: 0.9671 - val_loss: 10.0309 - val_accuracy: 0.9735\n",
            "Epoch 162/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0416 - accuracy: 0.9677 - val_loss: 10.0308 - val_accuracy: 0.9735\n",
            "Epoch 163/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0428 - accuracy: 0.9677 - val_loss: 10.0304 - val_accuracy: 0.9729\n",
            "Epoch 164/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0418 - accuracy: 0.9673 - val_loss: 10.0308 - val_accuracy: 0.9735\n",
            "Epoch 165/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0415 - accuracy: 0.9680 - val_loss: 10.0305 - val_accuracy: 0.9738\n",
            "Epoch 166/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0421 - accuracy: 0.9670 - val_loss: 10.0304 - val_accuracy: 0.9737\n",
            "Epoch 167/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0413 - accuracy: 0.9667 - val_loss: 10.0304 - val_accuracy: 0.9732\n",
            "Epoch 168/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0414 - accuracy: 0.9680 - val_loss: 10.0303 - val_accuracy: 0.9732\n",
            "Epoch 169/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0415 - accuracy: 0.9670 - val_loss: 10.0303 - val_accuracy: 0.9736\n",
            "Epoch 170/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0411 - accuracy: 0.9678 - val_loss: 10.0300 - val_accuracy: 0.9736\n",
            "Epoch 171/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0410 - accuracy: 0.9675 - val_loss: 10.0303 - val_accuracy: 0.9740\n",
            "Epoch 172/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0402 - accuracy: 0.9691 - val_loss: 10.0300 - val_accuracy: 0.9741\n",
            "Epoch 173/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0400 - accuracy: 0.9682 - val_loss: 10.0300 - val_accuracy: 0.9738\n",
            "Epoch 174/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0402 - accuracy: 0.9683 - val_loss: 10.0298 - val_accuracy: 0.9739\n",
            "Epoch 175/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0400 - accuracy: 0.9686 - val_loss: 10.0299 - val_accuracy: 0.9743\n",
            "Epoch 176/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0400 - accuracy: 0.9681 - val_loss: 10.0299 - val_accuracy: 0.9742\n",
            "Epoch 177/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0396 - accuracy: 0.9682 - val_loss: 10.0297 - val_accuracy: 0.9735\n",
            "Epoch 178/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0393 - accuracy: 0.9693 - val_loss: 10.0299 - val_accuracy: 0.9735\n",
            "Epoch 179/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0395 - accuracy: 0.9692 - val_loss: 10.0298 - val_accuracy: 0.9736\n",
            "Epoch 180/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0401 - accuracy: 0.9689 - val_loss: 10.0299 - val_accuracy: 0.9739\n",
            "Epoch 181/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0399 - accuracy: 0.9686 - val_loss: 10.0296 - val_accuracy: 0.9741\n",
            "Epoch 182/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0390 - accuracy: 0.9688 - val_loss: 10.0295 - val_accuracy: 0.9739\n",
            "Epoch 183/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0396 - accuracy: 0.9688 - val_loss: 10.0294 - val_accuracy: 0.9742\n",
            "Epoch 184/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0397 - accuracy: 0.9679 - val_loss: 10.0294 - val_accuracy: 0.9743\n",
            "Epoch 185/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0392 - accuracy: 0.9691 - val_loss: 10.0292 - val_accuracy: 0.9751\n",
            "Epoch 186/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0389 - accuracy: 0.9684 - val_loss: 10.0294 - val_accuracy: 0.9741\n",
            "Epoch 187/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0391 - accuracy: 0.9685 - val_loss: 10.0291 - val_accuracy: 0.9747\n",
            "Epoch 188/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0388 - accuracy: 0.9691 - val_loss: 10.0295 - val_accuracy: 0.9739\n",
            "Epoch 189/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0386 - accuracy: 0.9692 - val_loss: 10.0292 - val_accuracy: 0.9743\n",
            "Epoch 190/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0380 - accuracy: 0.9702 - val_loss: 10.0293 - val_accuracy: 0.9746\n",
            "Epoch 191/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0385 - accuracy: 0.9693 - val_loss: 10.0291 - val_accuracy: 0.9746\n",
            "Epoch 192/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0379 - accuracy: 0.9700 - val_loss: 10.0292 - val_accuracy: 0.9743\n",
            "Epoch 193/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0377 - accuracy: 0.9703 - val_loss: 10.0291 - val_accuracy: 0.9746\n",
            "Epoch 194/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0375 - accuracy: 0.9703 - val_loss: 10.0291 - val_accuracy: 0.9746\n",
            "Epoch 195/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0375 - accuracy: 0.9703 - val_loss: 10.0289 - val_accuracy: 0.9740\n",
            "Epoch 196/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0374 - accuracy: 0.9698 - val_loss: 10.0286 - val_accuracy: 0.9746\n",
            "Epoch 197/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0373 - accuracy: 0.9696 - val_loss: 10.0283 - val_accuracy: 0.9749\n",
            "Epoch 198/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0375 - accuracy: 0.9697 - val_loss: 10.0283 - val_accuracy: 0.9748\n",
            "Epoch 199/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0370 - accuracy: 0.9701 - val_loss: 10.0283 - val_accuracy: 0.9751\n",
            "Epoch 200/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0377 - accuracy: 0.9702 - val_loss: 10.0284 - val_accuracy: 0.9749\n",
            "Epoch 201/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0376 - accuracy: 0.9697 - val_loss: 10.0284 - val_accuracy: 0.9749\n",
            "Epoch 202/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0368 - accuracy: 0.9707 - val_loss: 10.0281 - val_accuracy: 0.9750\n",
            "Epoch 203/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0369 - accuracy: 0.9702 - val_loss: 10.0282 - val_accuracy: 0.9750\n",
            "Epoch 204/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0378 - accuracy: 0.9692 - val_loss: 10.0280 - val_accuracy: 0.9748\n",
            "Epoch 205/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0368 - accuracy: 0.9699 - val_loss: 10.0279 - val_accuracy: 0.9750\n",
            "Epoch 206/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0358 - accuracy: 0.9713 - val_loss: 10.0282 - val_accuracy: 0.9752\n",
            "Epoch 207/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0366 - accuracy: 0.9698 - val_loss: 10.0279 - val_accuracy: 0.9750\n",
            "Epoch 208/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0368 - accuracy: 0.9702 - val_loss: 10.0281 - val_accuracy: 0.9750\n",
            "Epoch 209/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0359 - accuracy: 0.9716 - val_loss: 10.0280 - val_accuracy: 0.9751\n",
            "Epoch 210/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0355 - accuracy: 0.9712 - val_loss: 10.0280 - val_accuracy: 0.9752\n",
            "Epoch 211/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0361 - accuracy: 0.9704 - val_loss: 10.0278 - val_accuracy: 0.9751\n",
            "Epoch 212/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0361 - accuracy: 0.9704 - val_loss: 10.0280 - val_accuracy: 0.9749\n",
            "Epoch 213/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0357 - accuracy: 0.9703 - val_loss: 10.0278 - val_accuracy: 0.9753\n",
            "Epoch 214/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0349 - accuracy: 0.9714 - val_loss: 10.0278 - val_accuracy: 0.9749\n",
            "Epoch 215/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0359 - accuracy: 0.9709 - val_loss: 10.0278 - val_accuracy: 0.9752\n",
            "Epoch 216/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0356 - accuracy: 0.9701 - val_loss: 10.0277 - val_accuracy: 0.9754\n",
            "Epoch 217/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0363 - accuracy: 0.9696 - val_loss: 10.0275 - val_accuracy: 0.9753\n",
            "Epoch 218/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0350 - accuracy: 0.9715 - val_loss: 10.0276 - val_accuracy: 0.9754\n",
            "Epoch 219/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0351 - accuracy: 0.9711 - val_loss: 10.0275 - val_accuracy: 0.9753\n",
            "Epoch 220/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0358 - accuracy: 0.9706 - val_loss: 10.0278 - val_accuracy: 0.9751\n",
            "Epoch 221/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0357 - accuracy: 0.9702 - val_loss: 10.0273 - val_accuracy: 0.9755\n",
            "Epoch 222/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0363 - accuracy: 0.9700 - val_loss: 10.0276 - val_accuracy: 0.9751\n",
            "Epoch 223/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0350 - accuracy: 0.9713 - val_loss: 10.0271 - val_accuracy: 0.9752\n",
            "Epoch 224/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0348 - accuracy: 0.9720 - val_loss: 10.0272 - val_accuracy: 0.9754\n",
            "Epoch 225/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0343 - accuracy: 0.9713 - val_loss: 10.0273 - val_accuracy: 0.9751\n",
            "Epoch 226/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0351 - accuracy: 0.9710 - val_loss: 10.0272 - val_accuracy: 0.9756\n",
            "Epoch 227/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0339 - accuracy: 0.9717 - val_loss: 10.0268 - val_accuracy: 0.9754\n",
            "Epoch 228/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0356 - accuracy: 0.9705 - val_loss: 10.0269 - val_accuracy: 0.9754\n",
            "Epoch 229/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0343 - accuracy: 0.9712 - val_loss: 10.0269 - val_accuracy: 0.9759\n",
            "Epoch 230/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0346 - accuracy: 0.9720 - val_loss: 10.0270 - val_accuracy: 0.9753\n",
            "Epoch 231/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0344 - accuracy: 0.9718 - val_loss: 10.0271 - val_accuracy: 0.9756\n",
            "Epoch 232/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0348 - accuracy: 0.9704 - val_loss: 10.0270 - val_accuracy: 0.9756\n",
            "Epoch 233/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0340 - accuracy: 0.9716 - val_loss: 10.0269 - val_accuracy: 0.9752\n",
            "Epoch 234/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0346 - accuracy: 0.9707 - val_loss: 10.0266 - val_accuracy: 0.9758\n",
            "Epoch 235/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0340 - accuracy: 0.9719 - val_loss: 10.0268 - val_accuracy: 0.9758\n",
            "Epoch 236/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0346 - accuracy: 0.9712 - val_loss: 10.0266 - val_accuracy: 0.9749\n",
            "Epoch 237/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0333 - accuracy: 0.9722 - val_loss: 10.0267 - val_accuracy: 0.9761\n",
            "Epoch 238/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0338 - accuracy: 0.9716 - val_loss: 10.0265 - val_accuracy: 0.9758\n",
            "Epoch 239/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0337 - accuracy: 0.9719 - val_loss: 10.0265 - val_accuracy: 0.9760\n",
            "Epoch 240/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0336 - accuracy: 0.9720 - val_loss: 10.0265 - val_accuracy: 0.9760\n",
            "Epoch 241/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0329 - accuracy: 0.9729 - val_loss: 10.0265 - val_accuracy: 0.9759\n",
            "Epoch 242/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0332 - accuracy: 0.9719 - val_loss: 10.0265 - val_accuracy: 0.9756\n",
            "Epoch 243/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0334 - accuracy: 0.9714 - val_loss: 10.0266 - val_accuracy: 0.9761\n",
            "Epoch 244/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0328 - accuracy: 0.9721 - val_loss: 10.0265 - val_accuracy: 0.9756\n",
            "Epoch 245/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0329 - accuracy: 0.9721 - val_loss: 10.0262 - val_accuracy: 0.9759\n",
            "Epoch 246/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0321 - accuracy: 0.9720 - val_loss: 10.0260 - val_accuracy: 0.9752\n",
            "Epoch 247/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0333 - accuracy: 0.9718 - val_loss: 10.0261 - val_accuracy: 0.9758\n",
            "Epoch 248/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0330 - accuracy: 0.9722 - val_loss: 10.0256 - val_accuracy: 0.9762\n",
            "Epoch 249/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0322 - accuracy: 0.9732 - val_loss: 10.0260 - val_accuracy: 0.9759\n",
            "Epoch 250/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0321 - accuracy: 0.9728 - val_loss: 10.0261 - val_accuracy: 0.9758\n",
            "Epoch 251/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0318 - accuracy: 0.9730 - val_loss: 10.0263 - val_accuracy: 0.9760\n",
            "Epoch 252/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0332 - accuracy: 0.9718 - val_loss: 10.0261 - val_accuracy: 0.9759\n",
            "Epoch 253/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0330 - accuracy: 0.9721 - val_loss: 10.0261 - val_accuracy: 0.9764\n",
            "Epoch 254/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0337 - accuracy: 0.9720 - val_loss: 10.0262 - val_accuracy: 0.9762\n",
            "Epoch 255/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0324 - accuracy: 0.9722 - val_loss: 10.0258 - val_accuracy: 0.9764\n",
            "Epoch 256/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0324 - accuracy: 0.9720 - val_loss: 10.0257 - val_accuracy: 0.9762\n",
            "Epoch 257/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0323 - accuracy: 0.9721 - val_loss: 10.0256 - val_accuracy: 0.9763\n",
            "Epoch 258/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0326 - accuracy: 0.9722 - val_loss: 10.0255 - val_accuracy: 0.9767\n",
            "Epoch 259/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0322 - accuracy: 0.9725 - val_loss: 10.0259 - val_accuracy: 0.9762\n",
            "Epoch 260/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0323 - accuracy: 0.9728 - val_loss: 10.0258 - val_accuracy: 0.9768\n",
            "Epoch 261/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0324 - accuracy: 0.9728 - val_loss: 10.0257 - val_accuracy: 0.9761\n",
            "Epoch 262/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0315 - accuracy: 0.9723 - val_loss: 10.0256 - val_accuracy: 0.9765\n",
            "Epoch 263/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0320 - accuracy: 0.9731 - val_loss: 10.0256 - val_accuracy: 0.9763\n",
            "Epoch 264/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0330 - accuracy: 0.9726 - val_loss: 10.0256 - val_accuracy: 0.9760\n",
            "Epoch 265/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0318 - accuracy: 0.9725 - val_loss: 10.0256 - val_accuracy: 0.9765\n",
            "Epoch 266/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0308 - accuracy: 0.9736 - val_loss: 10.0257 - val_accuracy: 0.9762\n",
            "Epoch 267/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0320 - accuracy: 0.9728 - val_loss: 10.0256 - val_accuracy: 0.9764\n",
            "Epoch 268/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0312 - accuracy: 0.9730 - val_loss: 10.0255 - val_accuracy: 0.9765\n",
            "Epoch 269/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0324 - accuracy: 0.9730 - val_loss: 10.0255 - val_accuracy: 0.9761\n",
            "Epoch 270/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0312 - accuracy: 0.9726 - val_loss: 10.0254 - val_accuracy: 0.9763\n",
            "Epoch 271/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0315 - accuracy: 0.9728 - val_loss: 10.0253 - val_accuracy: 0.9764\n",
            "Epoch 272/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0321 - accuracy: 0.9721 - val_loss: 10.0251 - val_accuracy: 0.9764\n",
            "Epoch 273/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0309 - accuracy: 0.9725 - val_loss: 10.0253 - val_accuracy: 0.9764\n",
            "Epoch 274/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0312 - accuracy: 0.9735 - val_loss: 10.0254 - val_accuracy: 0.9763\n",
            "Epoch 275/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0316 - accuracy: 0.9726 - val_loss: 10.0251 - val_accuracy: 0.9763\n",
            "Epoch 276/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0311 - accuracy: 0.9737 - val_loss: 10.0249 - val_accuracy: 0.9761\n",
            "Epoch 277/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0308 - accuracy: 0.9726 - val_loss: 10.0250 - val_accuracy: 0.9763\n",
            "Epoch 278/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0316 - accuracy: 0.9729 - val_loss: 10.0248 - val_accuracy: 0.9765\n",
            "Epoch 279/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0301 - accuracy: 0.9732 - val_loss: 10.0250 - val_accuracy: 0.9770\n",
            "Epoch 280/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0301 - accuracy: 0.9740 - val_loss: 10.0252 - val_accuracy: 0.9765\n",
            "Epoch 281/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0313 - accuracy: 0.9728 - val_loss: 10.0250 - val_accuracy: 0.9763\n",
            "Epoch 282/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0312 - accuracy: 0.9730 - val_loss: 10.0247 - val_accuracy: 0.9767\n",
            "Epoch 283/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0310 - accuracy: 0.9735 - val_loss: 10.0250 - val_accuracy: 0.9763\n",
            "Epoch 284/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0307 - accuracy: 0.9740 - val_loss: 10.0247 - val_accuracy: 0.9765\n",
            "Epoch 285/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0306 - accuracy: 0.9734 - val_loss: 10.0249 - val_accuracy: 0.9764\n",
            "Epoch 286/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0301 - accuracy: 0.9731 - val_loss: 10.0247 - val_accuracy: 0.9762\n",
            "Epoch 287/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0296 - accuracy: 0.9742 - val_loss: 10.0248 - val_accuracy: 0.9766\n",
            "Epoch 288/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0308 - accuracy: 0.9740 - val_loss: 10.0249 - val_accuracy: 0.9763\n",
            "Epoch 289/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0294 - accuracy: 0.9743 - val_loss: 10.0249 - val_accuracy: 0.9768\n",
            "Epoch 290/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0303 - accuracy: 0.9739 - val_loss: 10.0247 - val_accuracy: 0.9767\n",
            "Epoch 291/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0307 - accuracy: 0.9738 - val_loss: 10.0249 - val_accuracy: 0.9764\n",
            "Epoch 292/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0294 - accuracy: 0.9740 - val_loss: 10.0246 - val_accuracy: 0.9766\n",
            "Epoch 293/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0301 - accuracy: 0.9745 - val_loss: 10.0246 - val_accuracy: 0.9767\n",
            "Epoch 294/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0300 - accuracy: 0.9745 - val_loss: 10.0245 - val_accuracy: 0.9769\n",
            "Epoch 295/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0283 - accuracy: 0.9749 - val_loss: 10.0253 - val_accuracy: 0.9759\n",
            "Epoch 296/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0296 - accuracy: 0.9739 - val_loss: 10.0247 - val_accuracy: 0.9767\n",
            "Epoch 297/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0301 - accuracy: 0.9738 - val_loss: 10.0245 - val_accuracy: 0.9770\n",
            "Epoch 298/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0302 - accuracy: 0.9734 - val_loss: 10.0248 - val_accuracy: 0.9769\n",
            "Epoch 299/400\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 10.0296 - accuracy: 0.9741 - val_loss: 10.0246 - val_accuracy: 0.9763\n",
            "Epoch 300/400\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 10.0298 - accuracy: 0.9735 - val_loss: 10.0243 - val_accuracy: 0.9767\n",
            "Epoch 301/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0296 - accuracy: 0.9739 - val_loss: 10.0243 - val_accuracy: 0.9767\n",
            "Epoch 302/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0292 - accuracy: 0.9747 - val_loss: 10.0241 - val_accuracy: 0.9774\n",
            "Epoch 303/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0296 - accuracy: 0.9740 - val_loss: 10.0242 - val_accuracy: 0.9771\n",
            "Epoch 304/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0296 - accuracy: 0.9738 - val_loss: 10.0242 - val_accuracy: 0.9774\n",
            "Epoch 305/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0294 - accuracy: 0.9744 - val_loss: 10.0245 - val_accuracy: 0.9766\n",
            "Epoch 306/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0277 - accuracy: 0.9756 - val_loss: 10.0244 - val_accuracy: 0.9770\n",
            "Epoch 307/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0285 - accuracy: 0.9749 - val_loss: 10.0243 - val_accuracy: 0.9771\n",
            "Epoch 308/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0298 - accuracy: 0.9744 - val_loss: 10.0246 - val_accuracy: 0.9765\n",
            "Epoch 309/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0284 - accuracy: 0.9755 - val_loss: 10.0243 - val_accuracy: 0.9765\n",
            "Epoch 310/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0284 - accuracy: 0.9754 - val_loss: 10.0243 - val_accuracy: 0.9768\n",
            "Epoch 311/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0288 - accuracy: 0.9744 - val_loss: 10.0242 - val_accuracy: 0.9768\n",
            "Epoch 312/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0286 - accuracy: 0.9750 - val_loss: 10.0242 - val_accuracy: 0.9769\n",
            "Epoch 313/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0286 - accuracy: 0.9744 - val_loss: 10.0243 - val_accuracy: 0.9770\n",
            "Epoch 314/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0291 - accuracy: 0.9741 - val_loss: 10.0242 - val_accuracy: 0.9771\n",
            "Epoch 315/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0285 - accuracy: 0.9748 - val_loss: 10.0243 - val_accuracy: 0.9773\n",
            "Epoch 316/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0294 - accuracy: 0.9739 - val_loss: 10.0240 - val_accuracy: 0.9773\n",
            "Epoch 317/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0274 - accuracy: 0.9754 - val_loss: 10.0240 - val_accuracy: 0.9767\n",
            "Epoch 318/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0270 - accuracy: 0.9759 - val_loss: 10.0241 - val_accuracy: 0.9769\n",
            "Epoch 319/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0289 - accuracy: 0.9747 - val_loss: 10.0243 - val_accuracy: 0.9771\n",
            "Epoch 320/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0283 - accuracy: 0.9747 - val_loss: 10.0243 - val_accuracy: 0.9773\n",
            "Epoch 321/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0284 - accuracy: 0.9750 - val_loss: 10.0239 - val_accuracy: 0.9768\n",
            "Epoch 322/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0278 - accuracy: 0.9748 - val_loss: 10.0240 - val_accuracy: 0.9769\n",
            "Epoch 323/400\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 10.0285 - accuracy: 0.9745 - val_loss: 10.0240 - val_accuracy: 0.9771\n",
            "Epoch 324/400\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 10.0289 - accuracy: 0.9740 - val_loss: 10.0241 - val_accuracy: 0.9765\n",
            "Epoch 325/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0283 - accuracy: 0.9748 - val_loss: 10.0241 - val_accuracy: 0.9772\n",
            "Epoch 326/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0272 - accuracy: 0.9754 - val_loss: 10.0239 - val_accuracy: 0.9767\n",
            "Epoch 327/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0283 - accuracy: 0.9750 - val_loss: 10.0237 - val_accuracy: 0.9770\n",
            "Epoch 328/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0286 - accuracy: 0.9751 - val_loss: 10.0242 - val_accuracy: 0.9768\n",
            "Epoch 329/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0282 - accuracy: 0.9747 - val_loss: 10.0237 - val_accuracy: 0.9769\n",
            "Epoch 330/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0277 - accuracy: 0.9750 - val_loss: 10.0242 - val_accuracy: 0.9768\n",
            "Epoch 331/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0274 - accuracy: 0.9758 - val_loss: 10.0238 - val_accuracy: 0.9771\n",
            "Epoch 332/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0272 - accuracy: 0.9754 - val_loss: 10.0238 - val_accuracy: 0.9769\n",
            "Epoch 333/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0276 - accuracy: 0.9746 - val_loss: 10.0238 - val_accuracy: 0.9770\n",
            "Epoch 334/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0283 - accuracy: 0.9745 - val_loss: 10.0238 - val_accuracy: 0.9770\n",
            "Epoch 335/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0268 - accuracy: 0.9763 - val_loss: 10.0237 - val_accuracy: 0.9770\n",
            "Epoch 336/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0277 - accuracy: 0.9750 - val_loss: 10.0237 - val_accuracy: 0.9774\n",
            "Epoch 337/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0269 - accuracy: 0.9753 - val_loss: 10.0236 - val_accuracy: 0.9771\n",
            "Epoch 338/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0284 - accuracy: 0.9747 - val_loss: 10.0237 - val_accuracy: 0.9767\n",
            "Epoch 339/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0272 - accuracy: 0.9752 - val_loss: 10.0235 - val_accuracy: 0.9770\n",
            "Epoch 340/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0269 - accuracy: 0.9760 - val_loss: 10.0233 - val_accuracy: 0.9770\n",
            "Epoch 341/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0268 - accuracy: 0.9759 - val_loss: 10.0233 - val_accuracy: 0.9768\n",
            "Epoch 342/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0271 - accuracy: 0.9752 - val_loss: 10.0231 - val_accuracy: 0.9772\n",
            "Epoch 343/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0281 - accuracy: 0.9751 - val_loss: 10.0234 - val_accuracy: 0.9772\n",
            "Epoch 344/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0264 - accuracy: 0.9760 - val_loss: 10.0230 - val_accuracy: 0.9771\n",
            "Epoch 345/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0277 - accuracy: 0.9746 - val_loss: 10.0232 - val_accuracy: 0.9772\n",
            "Epoch 346/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0262 - accuracy: 0.9755 - val_loss: 10.0231 - val_accuracy: 0.9773\n",
            "Epoch 347/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0269 - accuracy: 0.9759 - val_loss: 10.0231 - val_accuracy: 0.9768\n",
            "Epoch 348/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0273 - accuracy: 0.9758 - val_loss: 10.0233 - val_accuracy: 0.9771\n",
            "Epoch 349/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0262 - accuracy: 0.9757 - val_loss: 10.0236 - val_accuracy: 0.9771\n",
            "Epoch 350/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0275 - accuracy: 0.9753 - val_loss: 10.0233 - val_accuracy: 0.9767\n",
            "Epoch 351/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0270 - accuracy: 0.9757 - val_loss: 10.0231 - val_accuracy: 0.9776\n",
            "Epoch 352/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0267 - accuracy: 0.9752 - val_loss: 10.0232 - val_accuracy: 0.9778\n",
            "Epoch 353/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0264 - accuracy: 0.9756 - val_loss: 10.0232 - val_accuracy: 0.9774\n",
            "Epoch 354/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0275 - accuracy: 0.9747 - val_loss: 10.0231 - val_accuracy: 0.9774\n",
            "Epoch 355/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0270 - accuracy: 0.9755 - val_loss: 10.0230 - val_accuracy: 0.9772\n",
            "Epoch 356/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0262 - accuracy: 0.9757 - val_loss: 10.0231 - val_accuracy: 0.9770\n",
            "Epoch 357/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0263 - accuracy: 0.9759 - val_loss: 10.0228 - val_accuracy: 0.9769\n",
            "Epoch 358/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0265 - accuracy: 0.9756 - val_loss: 10.0232 - val_accuracy: 0.9773\n",
            "Epoch 359/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0253 - accuracy: 0.9769 - val_loss: 10.0231 - val_accuracy: 0.9774\n",
            "Epoch 360/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0268 - accuracy: 0.9758 - val_loss: 10.0233 - val_accuracy: 0.9774\n",
            "Epoch 361/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0262 - accuracy: 0.9755 - val_loss: 10.0228 - val_accuracy: 0.9778\n",
            "Epoch 362/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0257 - accuracy: 0.9767 - val_loss: 10.0230 - val_accuracy: 0.9773\n",
            "Epoch 363/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0257 - accuracy: 0.9761 - val_loss: 10.0227 - val_accuracy: 0.9773\n",
            "Epoch 364/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0264 - accuracy: 0.9755 - val_loss: 10.0230 - val_accuracy: 0.9776\n",
            "Epoch 365/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0254 - accuracy: 0.9764 - val_loss: 10.0227 - val_accuracy: 0.9778\n",
            "Epoch 366/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0264 - accuracy: 0.9758 - val_loss: 10.0225 - val_accuracy: 0.9778\n",
            "Epoch 367/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0257 - accuracy: 0.9761 - val_loss: 10.0225 - val_accuracy: 0.9776\n",
            "Epoch 368/400\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 10.0256 - accuracy: 0.9756 - val_loss: 10.0227 - val_accuracy: 0.9781\n",
            "Epoch 369/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0248 - accuracy: 0.9773 - val_loss: 10.0227 - val_accuracy: 0.9773\n",
            "Epoch 370/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0259 - accuracy: 0.9762 - val_loss: 10.0225 - val_accuracy: 0.9773\n",
            "Epoch 371/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0246 - accuracy: 0.9770 - val_loss: 10.0229 - val_accuracy: 0.9774\n",
            "Epoch 372/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0264 - accuracy: 0.9753 - val_loss: 10.0228 - val_accuracy: 0.9772\n",
            "Epoch 373/400\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 10.0258 - accuracy: 0.9761 - val_loss: 10.0226 - val_accuracy: 0.9775\n",
            "Epoch 374/400\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 10.0252 - accuracy: 0.9771 - val_loss: 10.0226 - val_accuracy: 0.9774\n",
            "Epoch 375/400\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 10.0257 - accuracy: 0.9761 - val_loss: 10.0227 - val_accuracy: 0.9774\n",
            "Epoch 376/400\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 10.0259 - accuracy: 0.9759 - val_loss: 10.0228 - val_accuracy: 0.9781\n",
            "Epoch 377/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0250 - accuracy: 0.9766 - val_loss: 10.0229 - val_accuracy: 0.9775\n",
            "Epoch 378/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0245 - accuracy: 0.9765 - val_loss: 10.0227 - val_accuracy: 0.9777\n",
            "Epoch 379/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0257 - accuracy: 0.9761 - val_loss: 10.0225 - val_accuracy: 0.9779\n",
            "Epoch 380/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0245 - accuracy: 0.9768 - val_loss: 10.0226 - val_accuracy: 0.9774\n",
            "Epoch 381/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0252 - accuracy: 0.9762 - val_loss: 10.0226 - val_accuracy: 0.9779\n",
            "Epoch 382/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0251 - accuracy: 0.9758 - val_loss: 10.0226 - val_accuracy: 0.9780\n",
            "Epoch 383/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0263 - accuracy: 0.9762 - val_loss: 10.0229 - val_accuracy: 0.9780\n",
            "Epoch 384/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0256 - accuracy: 0.9765 - val_loss: 10.0224 - val_accuracy: 0.9778\n",
            "Epoch 385/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0248 - accuracy: 0.9768 - val_loss: 10.0225 - val_accuracy: 0.9780\n",
            "Epoch 386/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0254 - accuracy: 0.9767 - val_loss: 10.0223 - val_accuracy: 0.9785\n",
            "Epoch 387/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0260 - accuracy: 0.9764 - val_loss: 10.0224 - val_accuracy: 0.9779\n",
            "Epoch 388/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0248 - accuracy: 0.9768 - val_loss: 10.0224 - val_accuracy: 0.9781\n",
            "Epoch 389/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0239 - accuracy: 0.9779 - val_loss: 10.0222 - val_accuracy: 0.9781\n",
            "Epoch 390/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0247 - accuracy: 0.9767 - val_loss: 10.0224 - val_accuracy: 0.9783\n",
            "Epoch 391/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0243 - accuracy: 0.9770 - val_loss: 10.0227 - val_accuracy: 0.9781\n",
            "Epoch 392/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0254 - accuracy: 0.9766 - val_loss: 10.0224 - val_accuracy: 0.9782\n",
            "Epoch 393/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0246 - accuracy: 0.9768 - val_loss: 10.0223 - val_accuracy: 0.9780\n",
            "Epoch 394/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0244 - accuracy: 0.9772 - val_loss: 10.0224 - val_accuracy: 0.9777\n",
            "Epoch 395/400\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 10.0245 - accuracy: 0.9766 - val_loss: 10.0222 - val_accuracy: 0.9783\n",
            "Epoch 396/400\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 10.0243 - accuracy: 0.9767 - val_loss: 10.0221 - val_accuracy: 0.9781\n",
            "Epoch 397/400\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 10.0245 - accuracy: 0.9767 - val_loss: 10.0226 - val_accuracy: 0.9782\n",
            "Epoch 398/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0256 - accuracy: 0.9758 - val_loss: 10.0220 - val_accuracy: 0.9781\n",
            "Epoch 399/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0242 - accuracy: 0.9768 - val_loss: 10.0221 - val_accuracy: 0.9780\n",
            "Epoch 400/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.0243 - accuracy: 0.9771 - val_loss: 10.0225 - val_accuracy: 0.9784\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJRkLT1FjMf_",
        "outputId": "0b438c64-ff0d-43d7-a478-09b00512b87d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 10.02246379852295\n",
            "Test accuracy: 0.9783999919891357\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Best validation accuracy:', max(history.history['val_accuracy']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvnE0waEMhdp",
        "outputId": "3710ee13-446c-4ffd-8858-4ef283496707"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best validation accuracy: 0.9785000085830688\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Softmax Model"
      ],
      "metadata": {
        "id": "Lls-PoOdH5SJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(GaussianNoise(1.0, input_shape=(x_train.shape[1],)))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(10, use_bias=False, activation='softmax', kernel_regularizer=l2(0.0001), name='softmax'))"
      ],
      "metadata": {
        "id": "i-dU22OVH8dx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.SGD(learning_rate=0.0005,\n",
        "                                    decay=0.0005/400,\n",
        "                                    momentum=0.9)\n",
        "model.compile(optimizer = optimizer,\n",
        "              loss = 'categorical_crossentropy',\n",
        "              metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "ikKJ7-HDH8dy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 256\n",
        "epochs = 400\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size = batch_size,\n",
        "                    epochs = epochs,\n",
        "                    verbose = 1,\n",
        "                    validation_data = (x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c4f41dc-3922-4a02-ff44-90b132e94e20",
        "id": "HMRvrhvRH8dy"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.1873 - accuracy: 0.6593 - val_loss: 0.5968 - val_accuracy: 0.8562\n",
            "Epoch 2/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.5739 - accuracy: 0.8416 - val_loss: 0.4230 - val_accuracy: 0.8888\n",
            "Epoch 3/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.4655 - accuracy: 0.8660 - val_loss: 0.3587 - val_accuracy: 0.9024\n",
            "Epoch 4/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.4147 - accuracy: 0.8766 - val_loss: 0.3222 - val_accuracy: 0.9098\n",
            "Epoch 5/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.3822 - accuracy: 0.8857 - val_loss: 0.2978 - val_accuracy: 0.9151\n",
            "Epoch 6/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.3596 - accuracy: 0.8927 - val_loss: 0.2800 - val_accuracy: 0.9202\n",
            "Epoch 7/400\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.3442 - accuracy: 0.8963 - val_loss: 0.2653 - val_accuracy: 0.9230\n",
            "Epoch 8/400\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.3284 - accuracy: 0.9014 - val_loss: 0.2531 - val_accuracy: 0.9275\n",
            "Epoch 9/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.3148 - accuracy: 0.9054 - val_loss: 0.2436 - val_accuracy: 0.9304\n",
            "Epoch 10/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.3081 - accuracy: 0.9078 - val_loss: 0.2358 - val_accuracy: 0.9316\n",
            "Epoch 11/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.2952 - accuracy: 0.9109 - val_loss: 0.2275 - val_accuracy: 0.9346\n",
            "Epoch 12/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2896 - accuracy: 0.9124 - val_loss: 0.2211 - val_accuracy: 0.9361\n",
            "Epoch 13/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.2820 - accuracy: 0.9143 - val_loss: 0.2144 - val_accuracy: 0.9378\n",
            "Epoch 14/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2737 - accuracy: 0.9164 - val_loss: 0.2094 - val_accuracy: 0.9392\n",
            "Epoch 15/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2666 - accuracy: 0.9190 - val_loss: 0.2034 - val_accuracy: 0.9410\n",
            "Epoch 16/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2631 - accuracy: 0.9196 - val_loss: 0.1985 - val_accuracy: 0.9423\n",
            "Epoch 17/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2569 - accuracy: 0.9215 - val_loss: 0.1943 - val_accuracy: 0.9431\n",
            "Epoch 18/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2526 - accuracy: 0.9238 - val_loss: 0.1905 - val_accuracy: 0.9445\n",
            "Epoch 19/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.2462 - accuracy: 0.9251 - val_loss: 0.1874 - val_accuracy: 0.9451\n",
            "Epoch 20/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.2424 - accuracy: 0.9258 - val_loss: 0.1831 - val_accuracy: 0.9456\n",
            "Epoch 21/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.2382 - accuracy: 0.9268 - val_loss: 0.1803 - val_accuracy: 0.9465\n",
            "Epoch 22/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2335 - accuracy: 0.9284 - val_loss: 0.1764 - val_accuracy: 0.9485\n",
            "Epoch 23/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2310 - accuracy: 0.9295 - val_loss: 0.1739 - val_accuracy: 0.9486\n",
            "Epoch 24/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.2257 - accuracy: 0.9305 - val_loss: 0.1716 - val_accuracy: 0.9496\n",
            "Epoch 25/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2231 - accuracy: 0.9323 - val_loss: 0.1688 - val_accuracy: 0.9507\n",
            "Epoch 26/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2211 - accuracy: 0.9316 - val_loss: 0.1662 - val_accuracy: 0.9505\n",
            "Epoch 27/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.2148 - accuracy: 0.9341 - val_loss: 0.1637 - val_accuracy: 0.9515\n",
            "Epoch 28/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.2130 - accuracy: 0.9344 - val_loss: 0.1616 - val_accuracy: 0.9521\n",
            "Epoch 29/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2114 - accuracy: 0.9348 - val_loss: 0.1595 - val_accuracy: 0.9531\n",
            "Epoch 30/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.2092 - accuracy: 0.9352 - val_loss: 0.1572 - val_accuracy: 0.9535\n",
            "Epoch 31/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2068 - accuracy: 0.9364 - val_loss: 0.1550 - val_accuracy: 0.9543\n",
            "Epoch 32/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.2031 - accuracy: 0.9386 - val_loss: 0.1535 - val_accuracy: 0.9543\n",
            "Epoch 33/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1991 - accuracy: 0.9382 - val_loss: 0.1514 - val_accuracy: 0.9553\n",
            "Epoch 34/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1964 - accuracy: 0.9410 - val_loss: 0.1499 - val_accuracy: 0.9561\n",
            "Epoch 35/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1966 - accuracy: 0.9395 - val_loss: 0.1490 - val_accuracy: 0.9566\n",
            "Epoch 36/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1942 - accuracy: 0.9418 - val_loss: 0.1466 - val_accuracy: 0.9583\n",
            "Epoch 37/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1917 - accuracy: 0.9409 - val_loss: 0.1456 - val_accuracy: 0.9570\n",
            "Epoch 38/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1899 - accuracy: 0.9417 - val_loss: 0.1440 - val_accuracy: 0.9584\n",
            "Epoch 39/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1874 - accuracy: 0.9418 - val_loss: 0.1426 - val_accuracy: 0.9593\n",
            "Epoch 40/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1896 - accuracy: 0.9414 - val_loss: 0.1413 - val_accuracy: 0.9595\n",
            "Epoch 41/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1858 - accuracy: 0.9433 - val_loss: 0.1402 - val_accuracy: 0.9592\n",
            "Epoch 42/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1840 - accuracy: 0.9444 - val_loss: 0.1384 - val_accuracy: 0.9609\n",
            "Epoch 43/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1826 - accuracy: 0.9434 - val_loss: 0.1374 - val_accuracy: 0.9602\n",
            "Epoch 44/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1782 - accuracy: 0.9458 - val_loss: 0.1362 - val_accuracy: 0.9605\n",
            "Epoch 45/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1766 - accuracy: 0.9458 - val_loss: 0.1353 - val_accuracy: 0.9612\n",
            "Epoch 46/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1762 - accuracy: 0.9457 - val_loss: 0.1339 - val_accuracy: 0.9617\n",
            "Epoch 47/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1762 - accuracy: 0.9456 - val_loss: 0.1324 - val_accuracy: 0.9620\n",
            "Epoch 48/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1742 - accuracy: 0.9462 - val_loss: 0.1318 - val_accuracy: 0.9620\n",
            "Epoch 49/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1734 - accuracy: 0.9468 - val_loss: 0.1312 - val_accuracy: 0.9622\n",
            "Epoch 50/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1718 - accuracy: 0.9472 - val_loss: 0.1297 - val_accuracy: 0.9630\n",
            "Epoch 51/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1714 - accuracy: 0.9471 - val_loss: 0.1292 - val_accuracy: 0.9632\n",
            "Epoch 52/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1698 - accuracy: 0.9475 - val_loss: 0.1284 - val_accuracy: 0.9628\n",
            "Epoch 53/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1666 - accuracy: 0.9484 - val_loss: 0.1270 - val_accuracy: 0.9639\n",
            "Epoch 54/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1640 - accuracy: 0.9494 - val_loss: 0.1266 - val_accuracy: 0.9642\n",
            "Epoch 55/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1653 - accuracy: 0.9489 - val_loss: 0.1254 - val_accuracy: 0.9635\n",
            "Epoch 56/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1641 - accuracy: 0.9490 - val_loss: 0.1249 - val_accuracy: 0.9638\n",
            "Epoch 57/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1613 - accuracy: 0.9506 - val_loss: 0.1243 - val_accuracy: 0.9647\n",
            "Epoch 58/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1598 - accuracy: 0.9503 - val_loss: 0.1234 - val_accuracy: 0.9643\n",
            "Epoch 59/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1603 - accuracy: 0.9504 - val_loss: 0.1230 - val_accuracy: 0.9642\n",
            "Epoch 60/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1585 - accuracy: 0.9517 - val_loss: 0.1219 - val_accuracy: 0.9637\n",
            "Epoch 61/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1605 - accuracy: 0.9494 - val_loss: 0.1208 - val_accuracy: 0.9649\n",
            "Epoch 62/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1569 - accuracy: 0.9516 - val_loss: 0.1205 - val_accuracy: 0.9650\n",
            "Epoch 63/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1572 - accuracy: 0.9514 - val_loss: 0.1195 - val_accuracy: 0.9646\n",
            "Epoch 64/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1548 - accuracy: 0.9512 - val_loss: 0.1192 - val_accuracy: 0.9648\n",
            "Epoch 65/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1539 - accuracy: 0.9525 - val_loss: 0.1183 - val_accuracy: 0.9654\n",
            "Epoch 66/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1533 - accuracy: 0.9525 - val_loss: 0.1174 - val_accuracy: 0.9661\n",
            "Epoch 67/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1529 - accuracy: 0.9529 - val_loss: 0.1169 - val_accuracy: 0.9657\n",
            "Epoch 68/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1498 - accuracy: 0.9541 - val_loss: 0.1160 - val_accuracy: 0.9662\n",
            "Epoch 69/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1515 - accuracy: 0.9528 - val_loss: 0.1166 - val_accuracy: 0.9660\n",
            "Epoch 70/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1493 - accuracy: 0.9533 - val_loss: 0.1153 - val_accuracy: 0.9666\n",
            "Epoch 71/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1469 - accuracy: 0.9548 - val_loss: 0.1146 - val_accuracy: 0.9669\n",
            "Epoch 72/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1466 - accuracy: 0.9548 - val_loss: 0.1136 - val_accuracy: 0.9677\n",
            "Epoch 73/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1475 - accuracy: 0.9543 - val_loss: 0.1129 - val_accuracy: 0.9676\n",
            "Epoch 74/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1465 - accuracy: 0.9558 - val_loss: 0.1126 - val_accuracy: 0.9678\n",
            "Epoch 75/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1427 - accuracy: 0.9555 - val_loss: 0.1125 - val_accuracy: 0.9680\n",
            "Epoch 76/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1439 - accuracy: 0.9555 - val_loss: 0.1119 - val_accuracy: 0.9673\n",
            "Epoch 77/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1432 - accuracy: 0.9550 - val_loss: 0.1117 - val_accuracy: 0.9679\n",
            "Epoch 78/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1436 - accuracy: 0.9553 - val_loss: 0.1114 - val_accuracy: 0.9678\n",
            "Epoch 79/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1430 - accuracy: 0.9554 - val_loss: 0.1111 - val_accuracy: 0.9675\n",
            "Epoch 80/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1427 - accuracy: 0.9559 - val_loss: 0.1108 - val_accuracy: 0.9679\n",
            "Epoch 81/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1407 - accuracy: 0.9570 - val_loss: 0.1100 - val_accuracy: 0.9681\n",
            "Epoch 82/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1411 - accuracy: 0.9566 - val_loss: 0.1099 - val_accuracy: 0.9683\n",
            "Epoch 83/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1386 - accuracy: 0.9560 - val_loss: 0.1089 - val_accuracy: 0.9687\n",
            "Epoch 84/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1373 - accuracy: 0.9577 - val_loss: 0.1090 - val_accuracy: 0.9687\n",
            "Epoch 85/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1383 - accuracy: 0.9568 - val_loss: 0.1087 - val_accuracy: 0.9689\n",
            "Epoch 86/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1384 - accuracy: 0.9572 - val_loss: 0.1081 - val_accuracy: 0.9690\n",
            "Epoch 87/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1372 - accuracy: 0.9575 - val_loss: 0.1077 - val_accuracy: 0.9692\n",
            "Epoch 88/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1361 - accuracy: 0.9578 - val_loss: 0.1072 - val_accuracy: 0.9695\n",
            "Epoch 89/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1372 - accuracy: 0.9582 - val_loss: 0.1070 - val_accuracy: 0.9688\n",
            "Epoch 90/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1359 - accuracy: 0.9582 - val_loss: 0.1065 - val_accuracy: 0.9684\n",
            "Epoch 91/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1356 - accuracy: 0.9579 - val_loss: 0.1069 - val_accuracy: 0.9697\n",
            "Epoch 92/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1346 - accuracy: 0.9580 - val_loss: 0.1062 - val_accuracy: 0.9696\n",
            "Epoch 93/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1325 - accuracy: 0.9589 - val_loss: 0.1061 - val_accuracy: 0.9691\n",
            "Epoch 94/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1338 - accuracy: 0.9587 - val_loss: 0.1054 - val_accuracy: 0.9696\n",
            "Epoch 95/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1313 - accuracy: 0.9595 - val_loss: 0.1049 - val_accuracy: 0.9698\n",
            "Epoch 96/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1310 - accuracy: 0.9590 - val_loss: 0.1049 - val_accuracy: 0.9700\n",
            "Epoch 97/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1318 - accuracy: 0.9591 - val_loss: 0.1042 - val_accuracy: 0.9708\n",
            "Epoch 98/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1308 - accuracy: 0.9595 - val_loss: 0.1042 - val_accuracy: 0.9709\n",
            "Epoch 99/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1300 - accuracy: 0.9590 - val_loss: 0.1043 - val_accuracy: 0.9706\n",
            "Epoch 100/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1299 - accuracy: 0.9595 - val_loss: 0.1035 - val_accuracy: 0.9702\n",
            "Epoch 101/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1287 - accuracy: 0.9601 - val_loss: 0.1032 - val_accuracy: 0.9707\n",
            "Epoch 102/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1305 - accuracy: 0.9593 - val_loss: 0.1030 - val_accuracy: 0.9712\n",
            "Epoch 103/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1302 - accuracy: 0.9597 - val_loss: 0.1032 - val_accuracy: 0.9705\n",
            "Epoch 104/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1278 - accuracy: 0.9605 - val_loss: 0.1030 - val_accuracy: 0.9706\n",
            "Epoch 105/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1274 - accuracy: 0.9597 - val_loss: 0.1030 - val_accuracy: 0.9704\n",
            "Epoch 106/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1270 - accuracy: 0.9609 - val_loss: 0.1018 - val_accuracy: 0.9710\n",
            "Epoch 107/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1280 - accuracy: 0.9603 - val_loss: 0.1026 - val_accuracy: 0.9705\n",
            "Epoch 108/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1268 - accuracy: 0.9613 - val_loss: 0.1017 - val_accuracy: 0.9708\n",
            "Epoch 109/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1256 - accuracy: 0.9614 - val_loss: 0.1012 - val_accuracy: 0.9714\n",
            "Epoch 110/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1254 - accuracy: 0.9606 - val_loss: 0.1013 - val_accuracy: 0.9710\n",
            "Epoch 111/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1250 - accuracy: 0.9618 - val_loss: 0.1011 - val_accuracy: 0.9709\n",
            "Epoch 112/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1227 - accuracy: 0.9619 - val_loss: 0.1007 - val_accuracy: 0.9714\n",
            "Epoch 113/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1234 - accuracy: 0.9615 - val_loss: 0.1007 - val_accuracy: 0.9719\n",
            "Epoch 114/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1252 - accuracy: 0.9612 - val_loss: 0.1005 - val_accuracy: 0.9712\n",
            "Epoch 115/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1226 - accuracy: 0.9618 - val_loss: 0.1005 - val_accuracy: 0.9708\n",
            "Epoch 116/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1222 - accuracy: 0.9619 - val_loss: 0.0999 - val_accuracy: 0.9711\n",
            "Epoch 117/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1212 - accuracy: 0.9624 - val_loss: 0.0998 - val_accuracy: 0.9711\n",
            "Epoch 118/400\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.1203 - accuracy: 0.9621 - val_loss: 0.1005 - val_accuracy: 0.9708\n",
            "Epoch 119/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1222 - accuracy: 0.9612 - val_loss: 0.0995 - val_accuracy: 0.9706\n",
            "Epoch 120/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1212 - accuracy: 0.9620 - val_loss: 0.0983 - val_accuracy: 0.9715\n",
            "Epoch 121/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1204 - accuracy: 0.9614 - val_loss: 0.0984 - val_accuracy: 0.9710\n",
            "Epoch 122/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1215 - accuracy: 0.9627 - val_loss: 0.0984 - val_accuracy: 0.9715\n",
            "Epoch 123/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1207 - accuracy: 0.9623 - val_loss: 0.0979 - val_accuracy: 0.9719\n",
            "Epoch 124/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1197 - accuracy: 0.9623 - val_loss: 0.0977 - val_accuracy: 0.9719\n",
            "Epoch 125/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1200 - accuracy: 0.9630 - val_loss: 0.0984 - val_accuracy: 0.9714\n",
            "Epoch 126/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1173 - accuracy: 0.9637 - val_loss: 0.0973 - val_accuracy: 0.9720\n",
            "Epoch 127/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1194 - accuracy: 0.9625 - val_loss: 0.0976 - val_accuracy: 0.9722\n",
            "Epoch 128/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1177 - accuracy: 0.9630 - val_loss: 0.0970 - val_accuracy: 0.9721\n",
            "Epoch 129/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1190 - accuracy: 0.9635 - val_loss: 0.0968 - val_accuracy: 0.9716\n",
            "Epoch 130/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1178 - accuracy: 0.9632 - val_loss: 0.0967 - val_accuracy: 0.9720\n",
            "Epoch 131/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1165 - accuracy: 0.9638 - val_loss: 0.0964 - val_accuracy: 0.9718\n",
            "Epoch 132/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1153 - accuracy: 0.9641 - val_loss: 0.0965 - val_accuracy: 0.9718\n",
            "Epoch 133/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1151 - accuracy: 0.9638 - val_loss: 0.0966 - val_accuracy: 0.9721\n",
            "Epoch 134/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1139 - accuracy: 0.9653 - val_loss: 0.0963 - val_accuracy: 0.9720\n",
            "Epoch 135/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1132 - accuracy: 0.9649 - val_loss: 0.0960 - val_accuracy: 0.9725\n",
            "Epoch 136/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1152 - accuracy: 0.9639 - val_loss: 0.0954 - val_accuracy: 0.9721\n",
            "Epoch 137/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1150 - accuracy: 0.9634 - val_loss: 0.0955 - val_accuracy: 0.9722\n",
            "Epoch 138/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1131 - accuracy: 0.9642 - val_loss: 0.0951 - val_accuracy: 0.9729\n",
            "Epoch 139/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1142 - accuracy: 0.9642 - val_loss: 0.0951 - val_accuracy: 0.9730\n",
            "Epoch 140/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1134 - accuracy: 0.9649 - val_loss: 0.0951 - val_accuracy: 0.9728\n",
            "Epoch 141/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1145 - accuracy: 0.9642 - val_loss: 0.0945 - val_accuracy: 0.9725\n",
            "Epoch 142/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1136 - accuracy: 0.9644 - val_loss: 0.0944 - val_accuracy: 0.9729\n",
            "Epoch 143/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1134 - accuracy: 0.9652 - val_loss: 0.0939 - val_accuracy: 0.9722\n",
            "Epoch 144/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1131 - accuracy: 0.9645 - val_loss: 0.0942 - val_accuracy: 0.9733\n",
            "Epoch 145/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1136 - accuracy: 0.9652 - val_loss: 0.0942 - val_accuracy: 0.9729\n",
            "Epoch 146/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1127 - accuracy: 0.9651 - val_loss: 0.0936 - val_accuracy: 0.9732\n",
            "Epoch 147/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1111 - accuracy: 0.9658 - val_loss: 0.0937 - val_accuracy: 0.9730\n",
            "Epoch 148/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1116 - accuracy: 0.9658 - val_loss: 0.0940 - val_accuracy: 0.9723\n",
            "Epoch 149/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1094 - accuracy: 0.9664 - val_loss: 0.0936 - val_accuracy: 0.9730\n",
            "Epoch 150/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1132 - accuracy: 0.9653 - val_loss: 0.0937 - val_accuracy: 0.9732\n",
            "Epoch 151/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1115 - accuracy: 0.9648 - val_loss: 0.0937 - val_accuracy: 0.9730\n",
            "Epoch 152/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1105 - accuracy: 0.9649 - val_loss: 0.0932 - val_accuracy: 0.9738\n",
            "Epoch 153/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1084 - accuracy: 0.9667 - val_loss: 0.0933 - val_accuracy: 0.9739\n",
            "Epoch 154/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1111 - accuracy: 0.9655 - val_loss: 0.0929 - val_accuracy: 0.9738\n",
            "Epoch 155/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1093 - accuracy: 0.9662 - val_loss: 0.0930 - val_accuracy: 0.9740\n",
            "Epoch 156/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1092 - accuracy: 0.9664 - val_loss: 0.0934 - val_accuracy: 0.9739\n",
            "Epoch 157/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1090 - accuracy: 0.9665 - val_loss: 0.0925 - val_accuracy: 0.9742\n",
            "Epoch 158/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1084 - accuracy: 0.9662 - val_loss: 0.0926 - val_accuracy: 0.9737\n",
            "Epoch 159/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1087 - accuracy: 0.9667 - val_loss: 0.0930 - val_accuracy: 0.9739\n",
            "Epoch 160/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1079 - accuracy: 0.9670 - val_loss: 0.0922 - val_accuracy: 0.9744\n",
            "Epoch 161/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1084 - accuracy: 0.9666 - val_loss: 0.0924 - val_accuracy: 0.9738\n",
            "Epoch 162/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1082 - accuracy: 0.9660 - val_loss: 0.0920 - val_accuracy: 0.9732\n",
            "Epoch 163/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1074 - accuracy: 0.9668 - val_loss: 0.0918 - val_accuracy: 0.9739\n",
            "Epoch 164/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1088 - accuracy: 0.9665 - val_loss: 0.0917 - val_accuracy: 0.9737\n",
            "Epoch 165/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1059 - accuracy: 0.9666 - val_loss: 0.0915 - val_accuracy: 0.9738\n",
            "Epoch 166/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1080 - accuracy: 0.9666 - val_loss: 0.0909 - val_accuracy: 0.9738\n",
            "Epoch 167/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1066 - accuracy: 0.9676 - val_loss: 0.0907 - val_accuracy: 0.9740\n",
            "Epoch 168/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1072 - accuracy: 0.9671 - val_loss: 0.0917 - val_accuracy: 0.9731\n",
            "Epoch 169/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1059 - accuracy: 0.9674 - val_loss: 0.0914 - val_accuracy: 0.9735\n",
            "Epoch 170/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1054 - accuracy: 0.9675 - val_loss: 0.0908 - val_accuracy: 0.9743\n",
            "Epoch 171/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1048 - accuracy: 0.9672 - val_loss: 0.0913 - val_accuracy: 0.9740\n",
            "Epoch 172/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1053 - accuracy: 0.9664 - val_loss: 0.0906 - val_accuracy: 0.9746\n",
            "Epoch 173/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1041 - accuracy: 0.9674 - val_loss: 0.0905 - val_accuracy: 0.9745\n",
            "Epoch 174/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1053 - accuracy: 0.9669 - val_loss: 0.0907 - val_accuracy: 0.9739\n",
            "Epoch 175/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1042 - accuracy: 0.9677 - val_loss: 0.0903 - val_accuracy: 0.9742\n",
            "Epoch 176/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1068 - accuracy: 0.9665 - val_loss: 0.0903 - val_accuracy: 0.9742\n",
            "Epoch 177/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1042 - accuracy: 0.9674 - val_loss: 0.0904 - val_accuracy: 0.9742\n",
            "Epoch 178/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1049 - accuracy: 0.9675 - val_loss: 0.0900 - val_accuracy: 0.9742\n",
            "Epoch 179/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1043 - accuracy: 0.9674 - val_loss: 0.0897 - val_accuracy: 0.9744\n",
            "Epoch 180/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1030 - accuracy: 0.9688 - val_loss: 0.0899 - val_accuracy: 0.9745\n",
            "Epoch 181/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1048 - accuracy: 0.9681 - val_loss: 0.0900 - val_accuracy: 0.9744\n",
            "Epoch 182/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1045 - accuracy: 0.9675 - val_loss: 0.0900 - val_accuracy: 0.9742\n",
            "Epoch 183/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1042 - accuracy: 0.9672 - val_loss: 0.0894 - val_accuracy: 0.9744\n",
            "Epoch 184/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1043 - accuracy: 0.9674 - val_loss: 0.0892 - val_accuracy: 0.9743\n",
            "Epoch 185/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1025 - accuracy: 0.9678 - val_loss: 0.0889 - val_accuracy: 0.9745\n",
            "Epoch 186/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1018 - accuracy: 0.9679 - val_loss: 0.0888 - val_accuracy: 0.9745\n",
            "Epoch 187/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1024 - accuracy: 0.9676 - val_loss: 0.0889 - val_accuracy: 0.9741\n",
            "Epoch 188/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1035 - accuracy: 0.9672 - val_loss: 0.0890 - val_accuracy: 0.9745\n",
            "Epoch 189/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1001 - accuracy: 0.9679 - val_loss: 0.0891 - val_accuracy: 0.9742\n",
            "Epoch 190/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1026 - accuracy: 0.9677 - val_loss: 0.0883 - val_accuracy: 0.9746\n",
            "Epoch 191/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1014 - accuracy: 0.9684 - val_loss: 0.0884 - val_accuracy: 0.9749\n",
            "Epoch 192/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1024 - accuracy: 0.9682 - val_loss: 0.0882 - val_accuracy: 0.9748\n",
            "Epoch 193/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0995 - accuracy: 0.9699 - val_loss: 0.0882 - val_accuracy: 0.9747\n",
            "Epoch 194/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1012 - accuracy: 0.9681 - val_loss: 0.0878 - val_accuracy: 0.9749\n",
            "Epoch 195/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1020 - accuracy: 0.9683 - val_loss: 0.0888 - val_accuracy: 0.9743\n",
            "Epoch 196/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0982 - accuracy: 0.9696 - val_loss: 0.0882 - val_accuracy: 0.9747\n",
            "Epoch 197/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1010 - accuracy: 0.9685 - val_loss: 0.0883 - val_accuracy: 0.9748\n",
            "Epoch 198/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0981 - accuracy: 0.9699 - val_loss: 0.0888 - val_accuracy: 0.9746\n",
            "Epoch 199/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0989 - accuracy: 0.9691 - val_loss: 0.0882 - val_accuracy: 0.9746\n",
            "Epoch 200/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0992 - accuracy: 0.9691 - val_loss: 0.0882 - val_accuracy: 0.9747\n",
            "Epoch 201/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0998 - accuracy: 0.9692 - val_loss: 0.0883 - val_accuracy: 0.9746\n",
            "Epoch 202/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0994 - accuracy: 0.9692 - val_loss: 0.0880 - val_accuracy: 0.9755\n",
            "Epoch 203/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0992 - accuracy: 0.9689 - val_loss: 0.0880 - val_accuracy: 0.9750\n",
            "Epoch 204/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0999 - accuracy: 0.9685 - val_loss: 0.0870 - val_accuracy: 0.9755\n",
            "Epoch 205/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0975 - accuracy: 0.9699 - val_loss: 0.0873 - val_accuracy: 0.9753\n",
            "Epoch 206/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0983 - accuracy: 0.9701 - val_loss: 0.0878 - val_accuracy: 0.9751\n",
            "Epoch 207/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0973 - accuracy: 0.9699 - val_loss: 0.0874 - val_accuracy: 0.9753\n",
            "Epoch 208/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0974 - accuracy: 0.9695 - val_loss: 0.0868 - val_accuracy: 0.9753\n",
            "Epoch 209/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0981 - accuracy: 0.9698 - val_loss: 0.0869 - val_accuracy: 0.9754\n",
            "Epoch 210/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0981 - accuracy: 0.9692 - val_loss: 0.0872 - val_accuracy: 0.9754\n",
            "Epoch 211/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0993 - accuracy: 0.9685 - val_loss: 0.0872 - val_accuracy: 0.9752\n",
            "Epoch 212/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0994 - accuracy: 0.9688 - val_loss: 0.0874 - val_accuracy: 0.9753\n",
            "Epoch 213/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0970 - accuracy: 0.9698 - val_loss: 0.0870 - val_accuracy: 0.9754\n",
            "Epoch 214/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0959 - accuracy: 0.9705 - val_loss: 0.0868 - val_accuracy: 0.9755\n",
            "Epoch 215/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0967 - accuracy: 0.9698 - val_loss: 0.0868 - val_accuracy: 0.9752\n",
            "Epoch 216/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0955 - accuracy: 0.9709 - val_loss: 0.0869 - val_accuracy: 0.9756\n",
            "Epoch 217/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0967 - accuracy: 0.9701 - val_loss: 0.0870 - val_accuracy: 0.9749\n",
            "Epoch 218/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0939 - accuracy: 0.9705 - val_loss: 0.0870 - val_accuracy: 0.9752\n",
            "Epoch 219/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0955 - accuracy: 0.9700 - val_loss: 0.0866 - val_accuracy: 0.9756\n",
            "Epoch 220/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0955 - accuracy: 0.9704 - val_loss: 0.0861 - val_accuracy: 0.9758\n",
            "Epoch 221/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0969 - accuracy: 0.9698 - val_loss: 0.0868 - val_accuracy: 0.9752\n",
            "Epoch 222/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0955 - accuracy: 0.9706 - val_loss: 0.0864 - val_accuracy: 0.9749\n",
            "Epoch 223/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0950 - accuracy: 0.9704 - val_loss: 0.0869 - val_accuracy: 0.9752\n",
            "Epoch 224/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0938 - accuracy: 0.9710 - val_loss: 0.0865 - val_accuracy: 0.9757\n",
            "Epoch 225/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0945 - accuracy: 0.9705 - val_loss: 0.0864 - val_accuracy: 0.9757\n",
            "Epoch 226/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0930 - accuracy: 0.9712 - val_loss: 0.0865 - val_accuracy: 0.9755\n",
            "Epoch 227/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0955 - accuracy: 0.9698 - val_loss: 0.0861 - val_accuracy: 0.9754\n",
            "Epoch 228/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0961 - accuracy: 0.9699 - val_loss: 0.0860 - val_accuracy: 0.9757\n",
            "Epoch 229/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0947 - accuracy: 0.9707 - val_loss: 0.0861 - val_accuracy: 0.9756\n",
            "Epoch 230/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0960 - accuracy: 0.9691 - val_loss: 0.0855 - val_accuracy: 0.9758\n",
            "Epoch 231/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0936 - accuracy: 0.9701 - val_loss: 0.0853 - val_accuracy: 0.9763\n",
            "Epoch 232/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0936 - accuracy: 0.9711 - val_loss: 0.0857 - val_accuracy: 0.9755\n",
            "Epoch 233/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0930 - accuracy: 0.9708 - val_loss: 0.0859 - val_accuracy: 0.9752\n",
            "Epoch 234/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0911 - accuracy: 0.9711 - val_loss: 0.0858 - val_accuracy: 0.9754\n",
            "Epoch 235/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0942 - accuracy: 0.9712 - val_loss: 0.0860 - val_accuracy: 0.9756\n",
            "Epoch 236/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0928 - accuracy: 0.9714 - val_loss: 0.0854 - val_accuracy: 0.9761\n",
            "Epoch 237/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0927 - accuracy: 0.9710 - val_loss: 0.0854 - val_accuracy: 0.9756\n",
            "Epoch 238/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0917 - accuracy: 0.9714 - val_loss: 0.0849 - val_accuracy: 0.9763\n",
            "Epoch 239/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0928 - accuracy: 0.9708 - val_loss: 0.0850 - val_accuracy: 0.9766\n",
            "Epoch 240/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0943 - accuracy: 0.9705 - val_loss: 0.0849 - val_accuracy: 0.9760\n",
            "Epoch 241/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0930 - accuracy: 0.9708 - val_loss: 0.0848 - val_accuracy: 0.9761\n",
            "Epoch 242/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0912 - accuracy: 0.9721 - val_loss: 0.0847 - val_accuracy: 0.9761\n",
            "Epoch 243/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0916 - accuracy: 0.9716 - val_loss: 0.0848 - val_accuracy: 0.9760\n",
            "Epoch 244/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0927 - accuracy: 0.9711 - val_loss: 0.0852 - val_accuracy: 0.9754\n",
            "Epoch 245/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0931 - accuracy: 0.9710 - val_loss: 0.0846 - val_accuracy: 0.9762\n",
            "Epoch 246/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0935 - accuracy: 0.9708 - val_loss: 0.0842 - val_accuracy: 0.9764\n",
            "Epoch 247/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0928 - accuracy: 0.9714 - val_loss: 0.0853 - val_accuracy: 0.9757\n",
            "Epoch 248/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0893 - accuracy: 0.9724 - val_loss: 0.0846 - val_accuracy: 0.9760\n",
            "Epoch 249/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0936 - accuracy: 0.9717 - val_loss: 0.0843 - val_accuracy: 0.9761\n",
            "Epoch 250/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0911 - accuracy: 0.9716 - val_loss: 0.0842 - val_accuracy: 0.9761\n",
            "Epoch 251/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0905 - accuracy: 0.9720 - val_loss: 0.0845 - val_accuracy: 0.9759\n",
            "Epoch 252/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0924 - accuracy: 0.9712 - val_loss: 0.0849 - val_accuracy: 0.9753\n",
            "Epoch 253/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0913 - accuracy: 0.9713 - val_loss: 0.0849 - val_accuracy: 0.9758\n",
            "Epoch 254/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0908 - accuracy: 0.9718 - val_loss: 0.0843 - val_accuracy: 0.9762\n",
            "Epoch 255/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0912 - accuracy: 0.9725 - val_loss: 0.0843 - val_accuracy: 0.9761\n",
            "Epoch 256/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0901 - accuracy: 0.9715 - val_loss: 0.0845 - val_accuracy: 0.9760\n",
            "Epoch 257/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0894 - accuracy: 0.9719 - val_loss: 0.0839 - val_accuracy: 0.9767\n",
            "Epoch 258/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0890 - accuracy: 0.9722 - val_loss: 0.0837 - val_accuracy: 0.9763\n",
            "Epoch 259/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0892 - accuracy: 0.9725 - val_loss: 0.0844 - val_accuracy: 0.9762\n",
            "Epoch 260/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0906 - accuracy: 0.9714 - val_loss: 0.0837 - val_accuracy: 0.9761\n",
            "Epoch 261/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0893 - accuracy: 0.9717 - val_loss: 0.0837 - val_accuracy: 0.9762\n",
            "Epoch 262/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0902 - accuracy: 0.9715 - val_loss: 0.0841 - val_accuracy: 0.9758\n",
            "Epoch 263/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0894 - accuracy: 0.9726 - val_loss: 0.0839 - val_accuracy: 0.9762\n",
            "Epoch 264/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0875 - accuracy: 0.9734 - val_loss: 0.0838 - val_accuracy: 0.9763\n",
            "Epoch 265/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0900 - accuracy: 0.9725 - val_loss: 0.0840 - val_accuracy: 0.9764\n",
            "Epoch 266/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0888 - accuracy: 0.9726 - val_loss: 0.0839 - val_accuracy: 0.9758\n",
            "Epoch 267/400\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0878 - accuracy: 0.9724 - val_loss: 0.0838 - val_accuracy: 0.9759\n",
            "Epoch 268/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0876 - accuracy: 0.9732 - val_loss: 0.0834 - val_accuracy: 0.9764\n",
            "Epoch 269/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0884 - accuracy: 0.9725 - val_loss: 0.0838 - val_accuracy: 0.9762\n",
            "Epoch 270/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0893 - accuracy: 0.9717 - val_loss: 0.0837 - val_accuracy: 0.9766\n",
            "Epoch 271/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0870 - accuracy: 0.9732 - val_loss: 0.0840 - val_accuracy: 0.9759\n",
            "Epoch 272/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0897 - accuracy: 0.9721 - val_loss: 0.0840 - val_accuracy: 0.9763\n",
            "Epoch 273/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0885 - accuracy: 0.9731 - val_loss: 0.0837 - val_accuracy: 0.9764\n",
            "Epoch 274/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0877 - accuracy: 0.9731 - val_loss: 0.0834 - val_accuracy: 0.9768\n",
            "Epoch 275/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0864 - accuracy: 0.9728 - val_loss: 0.0833 - val_accuracy: 0.9760\n",
            "Epoch 276/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0888 - accuracy: 0.9719 - val_loss: 0.0834 - val_accuracy: 0.9760\n",
            "Epoch 277/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0885 - accuracy: 0.9725 - val_loss: 0.0831 - val_accuracy: 0.9764\n",
            "Epoch 278/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0863 - accuracy: 0.9729 - val_loss: 0.0832 - val_accuracy: 0.9761\n",
            "Epoch 279/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0868 - accuracy: 0.9720 - val_loss: 0.0831 - val_accuracy: 0.9762\n",
            "Epoch 280/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0873 - accuracy: 0.9728 - val_loss: 0.0832 - val_accuracy: 0.9762\n",
            "Epoch 281/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0879 - accuracy: 0.9722 - val_loss: 0.0834 - val_accuracy: 0.9761\n",
            "Epoch 282/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0856 - accuracy: 0.9734 - val_loss: 0.0831 - val_accuracy: 0.9762\n",
            "Epoch 283/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0871 - accuracy: 0.9732 - val_loss: 0.0829 - val_accuracy: 0.9764\n",
            "Epoch 284/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0871 - accuracy: 0.9733 - val_loss: 0.0829 - val_accuracy: 0.9762\n",
            "Epoch 285/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0863 - accuracy: 0.9736 - val_loss: 0.0826 - val_accuracy: 0.9767\n",
            "Epoch 286/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0863 - accuracy: 0.9732 - val_loss: 0.0828 - val_accuracy: 0.9770\n",
            "Epoch 287/400\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0871 - accuracy: 0.9736 - val_loss: 0.0830 - val_accuracy: 0.9766\n",
            "Epoch 288/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0854 - accuracy: 0.9741 - val_loss: 0.0828 - val_accuracy: 0.9766\n",
            "Epoch 289/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0875 - accuracy: 0.9730 - val_loss: 0.0824 - val_accuracy: 0.9767\n",
            "Epoch 290/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0874 - accuracy: 0.9730 - val_loss: 0.0823 - val_accuracy: 0.9764\n",
            "Epoch 291/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0862 - accuracy: 0.9737 - val_loss: 0.0828 - val_accuracy: 0.9766\n",
            "Epoch 292/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0886 - accuracy: 0.9719 - val_loss: 0.0821 - val_accuracy: 0.9766\n",
            "Epoch 293/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0850 - accuracy: 0.9742 - val_loss: 0.0821 - val_accuracy: 0.9771\n",
            "Epoch 294/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0847 - accuracy: 0.9731 - val_loss: 0.0821 - val_accuracy: 0.9770\n",
            "Epoch 295/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0855 - accuracy: 0.9736 - val_loss: 0.0821 - val_accuracy: 0.9768\n",
            "Epoch 296/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0866 - accuracy: 0.9729 - val_loss: 0.0826 - val_accuracy: 0.9768\n",
            "Epoch 297/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0858 - accuracy: 0.9728 - val_loss: 0.0824 - val_accuracy: 0.9767\n",
            "Epoch 298/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0866 - accuracy: 0.9732 - val_loss: 0.0820 - val_accuracy: 0.9770\n",
            "Epoch 299/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0868 - accuracy: 0.9734 - val_loss: 0.0820 - val_accuracy: 0.9770\n",
            "Epoch 300/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0845 - accuracy: 0.9733 - val_loss: 0.0820 - val_accuracy: 0.9772\n",
            "Epoch 301/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0862 - accuracy: 0.9728 - val_loss: 0.0818 - val_accuracy: 0.9772\n",
            "Epoch 302/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0864 - accuracy: 0.9734 - val_loss: 0.0821 - val_accuracy: 0.9770\n",
            "Epoch 303/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0869 - accuracy: 0.9728 - val_loss: 0.0818 - val_accuracy: 0.9769\n",
            "Epoch 304/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0846 - accuracy: 0.9735 - val_loss: 0.0822 - val_accuracy: 0.9773\n",
            "Epoch 305/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0844 - accuracy: 0.9738 - val_loss: 0.0819 - val_accuracy: 0.9771\n",
            "Epoch 306/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0850 - accuracy: 0.9737 - val_loss: 0.0813 - val_accuracy: 0.9772\n",
            "Epoch 307/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0860 - accuracy: 0.9721 - val_loss: 0.0814 - val_accuracy: 0.9772\n",
            "Epoch 308/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0857 - accuracy: 0.9731 - val_loss: 0.0816 - val_accuracy: 0.9769\n",
            "Epoch 309/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0829 - accuracy: 0.9745 - val_loss: 0.0818 - val_accuracy: 0.9769\n",
            "Epoch 310/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0839 - accuracy: 0.9743 - val_loss: 0.0824 - val_accuracy: 0.9770\n",
            "Epoch 311/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0850 - accuracy: 0.9739 - val_loss: 0.0818 - val_accuracy: 0.9771\n",
            "Epoch 312/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0828 - accuracy: 0.9748 - val_loss: 0.0818 - val_accuracy: 0.9769\n",
            "Epoch 313/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0839 - accuracy: 0.9741 - val_loss: 0.0822 - val_accuracy: 0.9767\n",
            "Epoch 314/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0853 - accuracy: 0.9736 - val_loss: 0.0820 - val_accuracy: 0.9767\n",
            "Epoch 315/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0828 - accuracy: 0.9745 - val_loss: 0.0817 - val_accuracy: 0.9772\n",
            "Epoch 316/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0823 - accuracy: 0.9742 - val_loss: 0.0818 - val_accuracy: 0.9768\n",
            "Epoch 317/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0806 - accuracy: 0.9761 - val_loss: 0.0811 - val_accuracy: 0.9770\n",
            "Epoch 318/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0837 - accuracy: 0.9737 - val_loss: 0.0811 - val_accuracy: 0.9771\n",
            "Epoch 319/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0830 - accuracy: 0.9746 - val_loss: 0.0807 - val_accuracy: 0.9770\n",
            "Epoch 320/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0842 - accuracy: 0.9736 - val_loss: 0.0809 - val_accuracy: 0.9769\n",
            "Epoch 321/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0835 - accuracy: 0.9747 - val_loss: 0.0816 - val_accuracy: 0.9768\n",
            "Epoch 322/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0846 - accuracy: 0.9739 - val_loss: 0.0819 - val_accuracy: 0.9770\n",
            "Epoch 323/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0844 - accuracy: 0.9739 - val_loss: 0.0816 - val_accuracy: 0.9776\n",
            "Epoch 324/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0835 - accuracy: 0.9741 - val_loss: 0.0816 - val_accuracy: 0.9771\n",
            "Epoch 325/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0826 - accuracy: 0.9740 - val_loss: 0.0816 - val_accuracy: 0.9772\n",
            "Epoch 326/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0835 - accuracy: 0.9742 - val_loss: 0.0809 - val_accuracy: 0.9773\n",
            "Epoch 327/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0818 - accuracy: 0.9745 - val_loss: 0.0808 - val_accuracy: 0.9771\n",
            "Epoch 328/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0815 - accuracy: 0.9750 - val_loss: 0.0813 - val_accuracy: 0.9768\n",
            "Epoch 329/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0808 - accuracy: 0.9748 - val_loss: 0.0807 - val_accuracy: 0.9771\n",
            "Epoch 330/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0818 - accuracy: 0.9747 - val_loss: 0.0811 - val_accuracy: 0.9773\n",
            "Epoch 331/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0818 - accuracy: 0.9751 - val_loss: 0.0809 - val_accuracy: 0.9773\n",
            "Epoch 332/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0819 - accuracy: 0.9748 - val_loss: 0.0809 - val_accuracy: 0.9771\n",
            "Epoch 333/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0823 - accuracy: 0.9752 - val_loss: 0.0805 - val_accuracy: 0.9773\n",
            "Epoch 334/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0817 - accuracy: 0.9750 - val_loss: 0.0810 - val_accuracy: 0.9769\n",
            "Epoch 335/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0810 - accuracy: 0.9753 - val_loss: 0.0808 - val_accuracy: 0.9775\n",
            "Epoch 336/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0835 - accuracy: 0.9742 - val_loss: 0.0806 - val_accuracy: 0.9772\n",
            "Epoch 337/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0825 - accuracy: 0.9746 - val_loss: 0.0801 - val_accuracy: 0.9773\n",
            "Epoch 338/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0812 - accuracy: 0.9741 - val_loss: 0.0800 - val_accuracy: 0.9778\n",
            "Epoch 339/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0804 - accuracy: 0.9753 - val_loss: 0.0803 - val_accuracy: 0.9778\n",
            "Epoch 340/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0823 - accuracy: 0.9750 - val_loss: 0.0806 - val_accuracy: 0.9773\n",
            "Epoch 341/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0811 - accuracy: 0.9750 - val_loss: 0.0805 - val_accuracy: 0.9776\n",
            "Epoch 342/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0790 - accuracy: 0.9753 - val_loss: 0.0805 - val_accuracy: 0.9774\n",
            "Epoch 343/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0785 - accuracy: 0.9758 - val_loss: 0.0807 - val_accuracy: 0.9772\n",
            "Epoch 344/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0811 - accuracy: 0.9743 - val_loss: 0.0803 - val_accuracy: 0.9771\n",
            "Epoch 345/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0818 - accuracy: 0.9749 - val_loss: 0.0802 - val_accuracy: 0.9776\n",
            "Epoch 346/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0811 - accuracy: 0.9748 - val_loss: 0.0802 - val_accuracy: 0.9774\n",
            "Epoch 347/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0812 - accuracy: 0.9747 - val_loss: 0.0799 - val_accuracy: 0.9773\n",
            "Epoch 348/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0806 - accuracy: 0.9748 - val_loss: 0.0800 - val_accuracy: 0.9776\n",
            "Epoch 349/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0821 - accuracy: 0.9741 - val_loss: 0.0796 - val_accuracy: 0.9774\n",
            "Epoch 350/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0813 - accuracy: 0.9745 - val_loss: 0.0795 - val_accuracy: 0.9775\n",
            "Epoch 351/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0812 - accuracy: 0.9750 - val_loss: 0.0800 - val_accuracy: 0.9776\n",
            "Epoch 352/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0813 - accuracy: 0.9747 - val_loss: 0.0801 - val_accuracy: 0.9774\n",
            "Epoch 353/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0827 - accuracy: 0.9743 - val_loss: 0.0798 - val_accuracy: 0.9774\n",
            "Epoch 354/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0798 - accuracy: 0.9755 - val_loss: 0.0795 - val_accuracy: 0.9777\n",
            "Epoch 355/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0789 - accuracy: 0.9756 - val_loss: 0.0797 - val_accuracy: 0.9776\n",
            "Epoch 356/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0799 - accuracy: 0.9751 - val_loss: 0.0795 - val_accuracy: 0.9777\n",
            "Epoch 357/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0791 - accuracy: 0.9761 - val_loss: 0.0796 - val_accuracy: 0.9777\n",
            "Epoch 358/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0793 - accuracy: 0.9754 - val_loss: 0.0799 - val_accuracy: 0.9776\n",
            "Epoch 359/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0798 - accuracy: 0.9748 - val_loss: 0.0793 - val_accuracy: 0.9780\n",
            "Epoch 360/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0808 - accuracy: 0.9745 - val_loss: 0.0793 - val_accuracy: 0.9776\n",
            "Epoch 361/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0785 - accuracy: 0.9762 - val_loss: 0.0795 - val_accuracy: 0.9775\n",
            "Epoch 362/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0793 - accuracy: 0.9754 - val_loss: 0.0797 - val_accuracy: 0.9776\n",
            "Epoch 363/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0796 - accuracy: 0.9755 - val_loss: 0.0790 - val_accuracy: 0.9777\n",
            "Epoch 364/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0792 - accuracy: 0.9762 - val_loss: 0.0792 - val_accuracy: 0.9782\n",
            "Epoch 365/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0788 - accuracy: 0.9757 - val_loss: 0.0791 - val_accuracy: 0.9775\n",
            "Epoch 366/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0787 - accuracy: 0.9755 - val_loss: 0.0794 - val_accuracy: 0.9776\n",
            "Epoch 367/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0807 - accuracy: 0.9754 - val_loss: 0.0796 - val_accuracy: 0.9776\n",
            "Epoch 368/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0781 - accuracy: 0.9760 - val_loss: 0.0797 - val_accuracy: 0.9775\n",
            "Epoch 369/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0775 - accuracy: 0.9760 - val_loss: 0.0797 - val_accuracy: 0.9774\n",
            "Epoch 370/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0778 - accuracy: 0.9759 - val_loss: 0.0792 - val_accuracy: 0.9772\n",
            "Epoch 371/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0785 - accuracy: 0.9758 - val_loss: 0.0789 - val_accuracy: 0.9776\n",
            "Epoch 372/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0778 - accuracy: 0.9755 - val_loss: 0.0791 - val_accuracy: 0.9776\n",
            "Epoch 373/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0789 - accuracy: 0.9751 - val_loss: 0.0787 - val_accuracy: 0.9775\n",
            "Epoch 374/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0780 - accuracy: 0.9757 - val_loss: 0.0788 - val_accuracy: 0.9775\n",
            "Epoch 375/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0779 - accuracy: 0.9758 - val_loss: 0.0793 - val_accuracy: 0.9779\n",
            "Epoch 376/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0803 - accuracy: 0.9757 - val_loss: 0.0788 - val_accuracy: 0.9775\n",
            "Epoch 377/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0783 - accuracy: 0.9761 - val_loss: 0.0794 - val_accuracy: 0.9773\n",
            "Epoch 378/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0793 - accuracy: 0.9758 - val_loss: 0.0787 - val_accuracy: 0.9777\n",
            "Epoch 379/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0774 - accuracy: 0.9757 - val_loss: 0.0786 - val_accuracy: 0.9777\n",
            "Epoch 380/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0767 - accuracy: 0.9762 - val_loss: 0.0782 - val_accuracy: 0.9781\n",
            "Epoch 381/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0789 - accuracy: 0.9761 - val_loss: 0.0787 - val_accuracy: 0.9778\n",
            "Epoch 382/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0797 - accuracy: 0.9752 - val_loss: 0.0784 - val_accuracy: 0.9781\n",
            "Epoch 383/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0766 - accuracy: 0.9763 - val_loss: 0.0787 - val_accuracy: 0.9778\n",
            "Epoch 384/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0789 - accuracy: 0.9757 - val_loss: 0.0784 - val_accuracy: 0.9780\n",
            "Epoch 385/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0769 - accuracy: 0.9765 - val_loss: 0.0783 - val_accuracy: 0.9780\n",
            "Epoch 386/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0762 - accuracy: 0.9767 - val_loss: 0.0785 - val_accuracy: 0.9780\n",
            "Epoch 387/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0773 - accuracy: 0.9764 - val_loss: 0.0788 - val_accuracy: 0.9777\n",
            "Epoch 388/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0779 - accuracy: 0.9754 - val_loss: 0.0781 - val_accuracy: 0.9780\n",
            "Epoch 389/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0772 - accuracy: 0.9769 - val_loss: 0.0785 - val_accuracy: 0.9781\n",
            "Epoch 390/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0789 - accuracy: 0.9754 - val_loss: 0.0779 - val_accuracy: 0.9783\n",
            "Epoch 391/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0770 - accuracy: 0.9765 - val_loss: 0.0782 - val_accuracy: 0.9779\n",
            "Epoch 392/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0775 - accuracy: 0.9763 - val_loss: 0.0781 - val_accuracy: 0.9781\n",
            "Epoch 393/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0759 - accuracy: 0.9761 - val_loss: 0.0776 - val_accuracy: 0.9780\n",
            "Epoch 394/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0773 - accuracy: 0.9766 - val_loss: 0.0778 - val_accuracy: 0.9779\n",
            "Epoch 395/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0767 - accuracy: 0.9769 - val_loss: 0.0777 - val_accuracy: 0.9778\n",
            "Epoch 396/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0746 - accuracy: 0.9772 - val_loss: 0.0781 - val_accuracy: 0.9784\n",
            "Epoch 397/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0762 - accuracy: 0.9760 - val_loss: 0.0778 - val_accuracy: 0.9785\n",
            "Epoch 398/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0766 - accuracy: 0.9763 - val_loss: 0.0780 - val_accuracy: 0.9779\n",
            "Epoch 399/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0765 - accuracy: 0.9764 - val_loss: 0.0781 - val_accuracy: 0.9775\n",
            "Epoch 400/400\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0776 - accuracy: 0.9761 - val_loss: 0.0776 - val_accuracy: 0.9782\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e699254f-e1c8-40e7-8750-c0dd15a4ea10",
        "id": "iw6vdsKHH8dz"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.07764852046966553\n",
            "Test accuracy: 0.9782000184059143\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Best validation accuracy:', max(history.history['val_accuracy']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smaZ_xGANdhB",
        "outputId": "d5557851-7fa2-4411-f934-cbee657c9223"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best validation accuracy: 0.9785000085830688\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CIFAR"
      ],
      "metadata": {
        "id": "-FqBVMj41ZGr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset"
      ],
      "metadata": {
        "id": "EvZONL_T1ZGy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ],
      "metadata": {
        "id": "DEaxJ6vC1ZGy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 10\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes)"
      ],
      "metadata": {
        "id": "dfor9FEl1ZG0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255.\n",
        "x_test /= 255.\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebd647dc-c182-43a5-d900-e6e1ff37b586",
        "id": "5Y-K247e1ZG1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50000 train samples\n",
            "10000 test samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Augmentation"
      ],
      "metadata": {
        "id": "hU_9xszaD-7C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(#zoom_range=0.1,\n",
        "                             #width_shift_range=0.1,\n",
        "                             #height_shift_range=0.1,\n",
        "                             horizontal_flip=True)\n",
        "it_train = datagen.flow(x_train, y_train)"
      ],
      "metadata": {
        "id": "iWMipsFBEJ-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SVM Model"
      ],
      "metadata": {
        "id": "Li1jzsYj1ZG3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The original paper suggested a convolutional network with the following specification:\n",
        "\n",
        "\n",
        "*   A Convolutional Network consisting of two convolutional layer\n",
        "*   The first convolutional layer had 32 5  5 filters with ReLU activation function\n",
        "*   The second convolutional layer had 64 5  5 filters with ReLU activation function\n",
        "*   Both pooling layers used max pooling and downsampled by a factor of 2\n",
        "*   The penultimate layer has 3072 hidden nodes and uses ReLU activation with a dropout rate of 0.2\n",
        "*   Horizontal reflection and jitter is applied to the data randomly\n",
        "Minibatch of 128 data cases\n",
        "\n",
        "\n",
        "But the problems of the paper are:\n",
        "\n",
        "\n",
        "*   It didnt specified the optimization algorithm, learning rate, etc.\n",
        "*   It didnt say anything about the number of epochs.\n",
        "*   And most importantly it didnt specified the regularization weight value ().\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-tn7Qcwn1ZG3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, (5, 5), input_shape=(32, 32, 3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(64, (5, 5), padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(3072, activation='relu', name='penultimate'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(10, use_bias=False, activation='tanh', name='svm'))"
      ],
      "metadata": {
        "id": "5dLFcobC1ZG3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
        "model.compile(optimizer = optimizer,\n",
        "              loss = svm_loss(model.get_layer('svm'), 0.2, 0.8),\n",
        "              metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "h-5n8gBA1ZG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "epochs = 50\n",
        "\n",
        "history = model.fit(it_train,\n",
        "                    batch_size = batch_size,\n",
        "                    epochs = epochs,\n",
        "                    verbose = 1,\n",
        "                    validation_data = (x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ef1826e-43c2-4b4c-c62d-8d61c4533354",
        "id": "XDfNTL671ZG4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 4.7940 - accuracy: 0.4027 - val_loss: 4.7685 - val_accuracy: 0.5055\n",
            "Epoch 2/50\n",
            "1563/1563 [==============================] - 12s 7ms/step - loss: 4.7119 - accuracy: 0.5810 - val_loss: 4.6663 - val_accuracy: 0.6137\n",
            "Epoch 3/50\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 4.6188 - accuracy: 0.6706 - val_loss: 4.6067 - val_accuracy: 0.6775\n",
            "Epoch 4/50\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 4.5565 - accuracy: 0.7194 - val_loss: 4.5771 - val_accuracy: 0.6961\n",
            "Epoch 5/50\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 4.5048 - accuracy: 0.7543 - val_loss: 4.5535 - val_accuracy: 0.7140\n",
            "Epoch 6/50\n",
            "1563/1563 [==============================] - 12s 7ms/step - loss: 4.4586 - accuracy: 0.7867 - val_loss: 4.5309 - val_accuracy: 0.7345\n",
            "Epoch 7/50\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 4.4173 - accuracy: 0.8119 - val_loss: 4.5295 - val_accuracy: 0.7406\n",
            "Epoch 8/50\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 4.3758 - accuracy: 0.8364 - val_loss: 4.5207 - val_accuracy: 0.7487\n",
            "Epoch 9/50\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 4.3386 - accuracy: 0.8595 - val_loss: 4.5112 - val_accuracy: 0.7578\n",
            "Epoch 10/50\n",
            "1563/1563 [==============================] - 12s 7ms/step - loss: 4.3029 - accuracy: 0.8804 - val_loss: 4.5100 - val_accuracy: 0.7586\n",
            "Epoch 11/50\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 4.2660 - accuracy: 0.9006 - val_loss: 4.5329 - val_accuracy: 0.7560\n",
            "Epoch 12/50\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 4.2338 - accuracy: 0.9164 - val_loss: 4.5322 - val_accuracy: 0.7620\n",
            "Epoch 13/50\n",
            "1563/1563 [==============================] - 12s 7ms/step - loss: 4.2015 - accuracy: 0.9318 - val_loss: 4.5497 - val_accuracy: 0.7629\n",
            "Epoch 14/50\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 4.1712 - accuracy: 0.9460 - val_loss: 4.5559 - val_accuracy: 0.7663\n",
            "Epoch 15/50\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 4.1459 - accuracy: 0.9567 - val_loss: 4.5853 - val_accuracy: 0.7663\n",
            "Epoch 16/50\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 4.1266 - accuracy: 0.9642 - val_loss: 4.5956 - val_accuracy: 0.7683\n",
            "Epoch 17/50\n",
            "1563/1563 [==============================] - 12s 7ms/step - loss: 4.1038 - accuracy: 0.9729 - val_loss: 4.6096 - val_accuracy: 0.7663\n",
            "Epoch 18/50\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 4.0882 - accuracy: 0.9776 - val_loss: 4.6412 - val_accuracy: 0.7665\n",
            "Epoch 19/50\n",
            "1563/1563 [==============================] - 12s 7ms/step - loss: 4.0732 - accuracy: 0.9825 - val_loss: 4.6745 - val_accuracy: 0.7637\n",
            "Epoch 20/50\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 4.0623 - accuracy: 0.9856 - val_loss: 4.6688 - val_accuracy: 0.7683\n",
            "Epoch 21/50\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 4.0540 - accuracy: 0.9882 - val_loss: 4.6815 - val_accuracy: 0.7693\n",
            "Epoch 22/50\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 4.0469 - accuracy: 0.9900 - val_loss: 4.6958 - val_accuracy: 0.7677\n",
            "Epoch 23/50\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 4.0381 - accuracy: 0.9924 - val_loss: 4.7119 - val_accuracy: 0.7708\n",
            "Epoch 24/50\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 4.0349 - accuracy: 0.9931 - val_loss: 4.7429 - val_accuracy: 0.7687\n",
            "Epoch 25/50\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 4.0302 - accuracy: 0.9940 - val_loss: 4.7307 - val_accuracy: 0.7709\n",
            "Epoch 26/50\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 4.0280 - accuracy: 0.9947 - val_loss: 4.7586 - val_accuracy: 0.7678\n",
            "Epoch 27/50\n",
            "1563/1563 [==============================] - 12s 7ms/step - loss: 4.0232 - accuracy: 0.9953 - val_loss: 4.7544 - val_accuracy: 0.7675\n",
            "Epoch 28/50\n",
            "1563/1563 [==============================] - 12s 7ms/step - loss: 4.0223 - accuracy: 0.9955 - val_loss: 4.7720 - val_accuracy: 0.7723\n",
            "Epoch 29/50\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 4.0205 - accuracy: 0.9958 - val_loss: 4.7747 - val_accuracy: 0.7730\n",
            "Epoch 30/50\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 4.0160 - accuracy: 0.9966 - val_loss: 4.7979 - val_accuracy: 0.7706\n",
            "Epoch 31/50\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 4.0162 - accuracy: 0.9968 - val_loss: 4.8104 - val_accuracy: 0.7687\n",
            "Epoch 32/50\n",
            "1563/1563 [==============================] - 12s 7ms/step - loss: 4.0146 - accuracy: 0.9972 - val_loss: 4.8396 - val_accuracy: 0.7606\n",
            "Epoch 33/50\n",
            "1563/1563 [==============================] - 12s 7ms/step - loss: 4.0137 - accuracy: 0.9973 - val_loss: 4.8324 - val_accuracy: 0.7693\n",
            "Epoch 34/50\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 4.0130 - accuracy: 0.9974 - val_loss: 4.8484 - val_accuracy: 0.7650\n",
            "Epoch 35/50\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 4.0139 - accuracy: 0.9968 - val_loss: 4.8263 - val_accuracy: 0.7681\n",
            "Epoch 36/50\n",
            "1563/1563 [==============================] - 12s 7ms/step - loss: 4.0101 - accuracy: 0.9977 - val_loss: 4.8319 - val_accuracy: 0.7723\n",
            "Epoch 37/50\n",
            "1563/1563 [==============================] - 12s 7ms/step - loss: 4.0104 - accuracy: 0.9978 - val_loss: 4.8465 - val_accuracy: 0.7676\n",
            "Epoch 38/50\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 4.0103 - accuracy: 0.9978 - val_loss: 4.8448 - val_accuracy: 0.7706\n",
            "Epoch 39/50\n",
            "1563/1563 [==============================] - 12s 7ms/step - loss: 4.0105 - accuracy: 0.9974 - val_loss: 4.8525 - val_accuracy: 0.7715\n",
            "Epoch 40/50\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 4.0088 - accuracy: 0.9979 - val_loss: 4.8565 - val_accuracy: 0.7714\n",
            "Epoch 41/50\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 4.0089 - accuracy: 0.9978 - val_loss: 4.8621 - val_accuracy: 0.7710\n",
            "Epoch 42/50\n",
            "1563/1563 [==============================] - 12s 7ms/step - loss: 4.0083 - accuracy: 0.9980 - val_loss: 4.8510 - val_accuracy: 0.7724\n",
            "Epoch 43/50\n",
            "1563/1563 [==============================] - 12s 7ms/step - loss: 4.0069 - accuracy: 0.9983 - val_loss: 4.8664 - val_accuracy: 0.7667\n",
            "Epoch 44/50\n",
            "1563/1563 [==============================] - 12s 7ms/step - loss: 4.0074 - accuracy: 0.9980 - val_loss: 4.8731 - val_accuracy: 0.7713\n",
            "Epoch 45/50\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 4.0062 - accuracy: 0.9982 - val_loss: 4.8930 - val_accuracy: 0.7662\n",
            "Epoch 46/50\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 4.0059 - accuracy: 0.9984 - val_loss: 4.8745 - val_accuracy: 0.7680\n",
            "Epoch 47/50\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 4.0061 - accuracy: 0.9985 - val_loss: 4.8666 - val_accuracy: 0.7708\n",
            "Epoch 48/50\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 4.0068 - accuracy: 0.9983 - val_loss: 4.9115 - val_accuracy: 0.7650\n",
            "Epoch 49/50\n",
            "1563/1563 [==============================] - 12s 7ms/step - loss: 4.0044 - accuracy: 0.9986 - val_loss: 4.9017 - val_accuracy: 0.7673\n",
            "Epoch 50/50\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 4.0058 - accuracy: 0.9980 - val_loss: 4.9001 - val_accuracy: 0.7702\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "id": "h7ZEtWpF1ZG5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56f05bd5-de44-47fc-e01c-5bcc181748bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 4.900073528289795\n",
            "Test accuracy: 0.7702000141143799\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Best validation accuracy:', max(history.history['val_accuracy']))"
      ],
      "metadata": {
        "id": "YBKmQ-Wl1ZG5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5403fd03-58b0-4d5d-b635-b75d01f3f6bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best validation accuracy: 0.7730000019073486\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Softmax Model"
      ],
      "metadata": {
        "id": "myacSwPt1ZG5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, (5, 5), input_shape=(32, 32, 3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(64, (5, 5), padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(3072, activation='relu', name='penultimate'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(num_classes, activation='softmax'))"
      ],
      "metadata": {
        "id": "5F1Aip0Y1ZG6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss = 'categorical_crossentropy',\n",
        "              metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "whVu-I-v1ZG6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "epochs = 50\n",
        "\n",
        "history = model.fit(it_train,\n",
        "                    batch_size = batch_size,\n",
        "                    epochs = epochs,\n",
        "                    verbose = 1,\n",
        "                    validation_data = (x_test, y_test))"
      ],
      "metadata": {
        "id": "tun9iROO1ZG6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e90fcfe-d214-4eae-ae7b-213d31dcaf65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1563/1563 [==============================] - 12s 7ms/step - loss: 1.5164 - accuracy: 0.4576 - val_loss: 1.2396 - val_accuracy: 0.5631\n",
            "Epoch 2/50\n",
            "1563/1563 [==============================] - 12s 7ms/step - loss: 1.1866 - accuracy: 0.5825 - val_loss: 1.1483 - val_accuracy: 0.5866\n",
            "Epoch 3/50\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 1.0462 - accuracy: 0.6329 - val_loss: 0.9925 - val_accuracy: 0.6525\n",
            "Epoch 4/50\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.9577 - accuracy: 0.6643 - val_loss: 0.9550 - val_accuracy: 0.6669\n",
            "Epoch 5/50\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.8864 - accuracy: 0.6908 - val_loss: 0.9107 - val_accuracy: 0.6797\n",
            "Epoch 6/50\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.8253 - accuracy: 0.7142 - val_loss: 0.9020 - val_accuracy: 0.6860\n",
            "Epoch 7/50\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.7732 - accuracy: 0.7306 - val_loss: 0.8440 - val_accuracy: 0.7066\n",
            "Epoch 8/50\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.7248 - accuracy: 0.7503 - val_loss: 0.8016 - val_accuracy: 0.7232\n",
            "Epoch 9/50\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.6789 - accuracy: 0.7658 - val_loss: 0.8216 - val_accuracy: 0.7211\n",
            "Epoch 10/50\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.6374 - accuracy: 0.7803 - val_loss: 0.7986 - val_accuracy: 0.7256\n",
            "Epoch 11/50\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.5923 - accuracy: 0.7953 - val_loss: 0.7561 - val_accuracy: 0.7390\n",
            "Epoch 12/50\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.5527 - accuracy: 0.8107 - val_loss: 0.7887 - val_accuracy: 0.7319\n",
            "Epoch 13/50\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.5159 - accuracy: 0.8244 - val_loss: 0.7393 - val_accuracy: 0.7525\n",
            "Epoch 14/50\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.4721 - accuracy: 0.8420 - val_loss: 0.7416 - val_accuracy: 0.7483\n",
            "Epoch 15/50\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.4355 - accuracy: 0.8528 - val_loss: 0.7317 - val_accuracy: 0.7528\n",
            "Epoch 16/50\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.3993 - accuracy: 0.8667 - val_loss: 0.7446 - val_accuracy: 0.7543\n",
            "Epoch 17/50\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.3614 - accuracy: 0.8792 - val_loss: 0.7758 - val_accuracy: 0.7506\n",
            "Epoch 18/50\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.3316 - accuracy: 0.8897 - val_loss: 0.7430 - val_accuracy: 0.7565\n",
            "Epoch 19/50\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.2972 - accuracy: 0.9028 - val_loss: 0.7678 - val_accuracy: 0.7595\n",
            "Epoch 20/50\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.2693 - accuracy: 0.9129 - val_loss: 0.7539 - val_accuracy: 0.7644\n",
            "Epoch 21/50\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.2420 - accuracy: 0.9221 - val_loss: 0.7554 - val_accuracy: 0.7675\n",
            "Epoch 22/50\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.2166 - accuracy: 0.9311 - val_loss: 0.7715 - val_accuracy: 0.7618\n",
            "Epoch 23/50\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.1914 - accuracy: 0.9394 - val_loss: 0.8151 - val_accuracy: 0.7680\n",
            "Epoch 24/50\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.1707 - accuracy: 0.9465 - val_loss: 0.8498 - val_accuracy: 0.7596\n",
            "Epoch 25/50\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.1494 - accuracy: 0.9541 - val_loss: 0.8491 - val_accuracy: 0.7656\n",
            "Epoch 26/50\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.1333 - accuracy: 0.9578 - val_loss: 0.8611 - val_accuracy: 0.7633\n",
            "Epoch 27/50\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.1208 - accuracy: 0.9634 - val_loss: 0.8979 - val_accuracy: 0.7655\n",
            "Epoch 28/50\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.1074 - accuracy: 0.9666 - val_loss: 0.9107 - val_accuracy: 0.7684\n",
            "Epoch 29/50\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0935 - accuracy: 0.9718 - val_loss: 0.9415 - val_accuracy: 0.7637\n",
            "Epoch 30/50\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0856 - accuracy: 0.9748 - val_loss: 0.9569 - val_accuracy: 0.7682\n",
            "Epoch 31/50\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0771 - accuracy: 0.9766 - val_loss: 0.9714 - val_accuracy: 0.7652\n",
            "Epoch 32/50\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0707 - accuracy: 0.9795 - val_loss: 1.0100 - val_accuracy: 0.7666\n",
            "Epoch 33/50\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0643 - accuracy: 0.9812 - val_loss: 1.0283 - val_accuracy: 0.7642\n",
            "Epoch 34/50\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0603 - accuracy: 0.9832 - val_loss: 1.0515 - val_accuracy: 0.7617\n",
            "Epoch 35/50\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0563 - accuracy: 0.9829 - val_loss: 1.0944 - val_accuracy: 0.7551\n",
            "Epoch 36/50\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0507 - accuracy: 0.9850 - val_loss: 1.1366 - val_accuracy: 0.7647\n",
            "Epoch 37/50\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0490 - accuracy: 0.9852 - val_loss: 1.0883 - val_accuracy: 0.7663\n",
            "Epoch 38/50\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0459 - accuracy: 0.9865 - val_loss: 1.1261 - val_accuracy: 0.7686\n",
            "Epoch 39/50\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0424 - accuracy: 0.9878 - val_loss: 1.1345 - val_accuracy: 0.7711\n",
            "Epoch 40/50\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0409 - accuracy: 0.9880 - val_loss: 1.1589 - val_accuracy: 0.7718\n",
            "Epoch 41/50\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0376 - accuracy: 0.9891 - val_loss: 1.1861 - val_accuracy: 0.7593\n",
            "Epoch 42/50\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0374 - accuracy: 0.9891 - val_loss: 1.2328 - val_accuracy: 0.7630\n",
            "Epoch 43/50\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0332 - accuracy: 0.9904 - val_loss: 1.2233 - val_accuracy: 0.7671\n",
            "Epoch 44/50\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0346 - accuracy: 0.9895 - val_loss: 1.1864 - val_accuracy: 0.7623\n",
            "Epoch 45/50\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0327 - accuracy: 0.9903 - val_loss: 1.2112 - val_accuracy: 0.7723\n",
            "Epoch 46/50\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0285 - accuracy: 0.9911 - val_loss: 1.2864 - val_accuracy: 0.7620\n",
            "Epoch 47/50\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0307 - accuracy: 0.9902 - val_loss: 1.2340 - val_accuracy: 0.7661\n",
            "Epoch 48/50\n",
            "1563/1563 [==============================] - 12s 7ms/step - loss: 0.0281 - accuracy: 0.9917 - val_loss: 1.2425 - val_accuracy: 0.7660\n",
            "Epoch 49/50\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0300 - accuracy: 0.9910 - val_loss: 1.3016 - val_accuracy: 0.7641\n",
            "Epoch 50/50\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0270 - accuracy: 0.9920 - val_loss: 1.2834 - val_accuracy: 0.7638\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "id": "MqEClnPa1ZG7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e530d78-c2e0-44cc-fc4d-edb3a71324f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 1.2834279537200928\n",
            "Test accuracy: 0.7638000249862671\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Best validation accuracy:', max(history.history['val_accuracy']))"
      ],
      "metadata": {
        "id": "7aI3V2r31ZG7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "045b5b03-d3f2-4066-f88d-5bec3d483edf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best validation accuracy: 0.7723000049591064\n"
          ]
        }
      ]
    }
  ]
}